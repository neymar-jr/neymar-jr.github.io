[{"categories":["2021思考"],"content":"​ 今天和大姨交流了一下，主要有几个观点得到了修正： ​ 第一，对于和身边的人无法深入交流而产生的孤独感，不要仅仅因为观察到身边同龄的人和自己想法不一样，就片面的的出我在这个世界上是孤独的，你只是忘记了跟研究生学长学姐，导师，辅导员等比你阅历丰富的人进行的愉快的交流，等到更大的平台，身边就会出现更多深入思考的人，我这种对待孤独的悲观情绪确实是主管臆想了，这部分被大姨修正了。 ​ 第二，对于自身不足，以及与身边人不经意间比较产生的落差，大姨表达了一个观点，我很赞同，每个人价值观不同，导致对什么是好的评判标准不同，所以盲目的按照自己的评价体系去评判别人，甚至与自身境遇比较是伪命题。举个例子，一个辛勤劳作的农民和一个社会地位高，资源多的”成功“人士，光从快乐这个指标来看，农民不占下风，比如混迹于娱乐圈的人，个个物质极大丰富，仿佛生活在共产主义社会，但是仅从媒体曝出冰山一角的负面新闻我们就能得知，至少其中有部分人精神是极其空虚的，他们迷失在极大的物质刺激中，失去了人生的方向标，陈羽凡，吴秀波等等，所以从单一指标去衡量好坏是极其不科学的。 ​ 第三，是否应该有同时做好几件事的能力，这个没有定论，因为事情过于笼统，具体是什么事情？重要程度如何？紧急程度如何？一旦考虑这些条件，结论就清晰了，对于重要且紧急的事情，尽可能串行做，对于不重要且紧急和不紧急且重要的事情就可以分出些精力并行去做，所以我们得出结论的时候一定注意检查条件呐。 ​ 第四，自己对自己的看法，一直对自己都是挑剔的态度，很少肯定自己，这样固然有好处，即意识到自己渺小的人才可能有成长，但物极必反，过度贬低自己就容易陷入盲目自卑，即这个事情还没尝试就否定自己，我自己是体验过这种情绪的，初中高中尝试篮球，始终没能产生自信，每次打之前都会否定自己，但后来看篮球基本上就是个熟练，身体大于技巧的运动，哈哈。至于后来踢了足球，最开始还是盲目自卑，总想着，这东西我怎么可能做好呢，固然就导致害怕踢球，后来真正打破这个循环的还是自己逐渐深入后，发现了足球的乐趣，我始终对有自己爱好，能沉浸于自己那一隅的人抱有敬意，想想这可能就是刘晴老师说的纯粹，兴趣的力量是巨大的，每周五都会投入精力研究过人技巧，量变产生质变，只是我们人哈，很难做到高瞻远瞩，短期没有收获就容易放弃，我比较兴趣，在较短的时间内还是有显著提高的，顺其自然也就坚持了下来，所以后来每次一讨论兴趣，爱好这些话题，我总是给出定义，很少有人天生就喜欢什么，只有有了一定的积累，即入门了，才能逐渐体会到其乐趣，最后成为爱好。浅尝辄止就下结论说，我不喜欢这个，是不是就显得幼稚了？ ​ 最后说说未来，今天生了场病，可能是很久没生病了，比较痛苦，思考了下，自己已经很久没有锻炼了，小小的肠胃病却让我感受到了生命和健康的珍贵，我们真的要认真照顾自己，做所有事都拼命追求完美最后可能发现自己沿途少了很多快乐，同时失去了健康也追悔莫及。这不就是我说的，从一开始，他们所做的一切都与他们的初衷背道而驰，光是想想都觉得可怕，哈哈。 ","date":"2021-03-27","objectID":"/3%E6%9C%8827%E6%97%A5%E6%80%BB%E7%BB%93/:0:0","tags":["思考"],"title":"3月27日总结","uri":"/3%E6%9C%8827%E6%97%A5%E6%80%BB%E7%BB%93/"},{"categories":["2021思考"],"content":"从20号出复试线到现在，这几天情绪起伏比较大，从最开始的失落，失望到之后的颓废，无力，到今天积极，振作，经历了一段不短的心路历程，可能这也是一种成长，最近积极努力去做好眼前的每一件事，至于时运就不是我能掌控的了，哈哈。 下午收到了一封邮件，只有简短四个字，过线没有？，迅速看了作者邮箱，脑子里闪过一个想法，哦可能是之前联系过的导师，上教师主页查看了一下，是个很好的年轻的老师，所在的实验室在哈工大虽不是最好，但可以说在考研中是最好的也不为过，仔细想想，如果明年考了370是不是也就顶多来这个实验室了，顿时怅然若失。整理完思绪，剩下的就是落寞，过线，没过线，一字之差，但却可以控制一个人一年的精力，一瞬间让我联想到神之类的概念，是不是连续经历这样的挫折的人容易陷入虚无主义，之后靠宗教信仰振作，远离尘世，得到所谓的解脱。考研是神吗，是，因为结果能一定程度决定一个人的命运，又不是，神这个概念可以说是我们人无法干涉的，但考研不是，按科学的方法做出足够的努力就能很大程度干涉，所以我们应该怎么对待考研这摊子事，我们不知道学校的级别和难度是否匹配，比如中南计算机学硕335，专硕就370，在我眼里这两个都不难，只考一门数据结构嘛，把所有算法都实现一遍，背下来都能做到，我陷入了一种抱怨的情绪中，抱怨什么呢？抱怨考研这摊子事不公平，就仿佛有自己的意志似的，总会偏爱一些人，冷落一些人，就没法做到完全公平，即学校实力和难度匹配。但耿队的一句话点醒了我，这条路不是我们自己选择的吗？对啊，正是因为我们追求更高的平台，所以才挑战实力更强的学校，承担了更大的风险。试想一下，如果当时没有遵从自己的理想，去哈工大学自然语言处理，而是为了降低风险考中南，就算考上了，凭我完美主义的性格，大概还是会有遗憾吧。人们经常说年轻人和老年人的区别是什么？第一个是很直观是年龄，第二个我更看重，是一种闯劲，就是不满足于安稳的生活，挑战自己，走出舒适圈。所以，我们怎么评判一件事值不值得遗憾？拿考研举例，就是说回看当时的自己，每天有没有逃避考研这摊子事，每天是不是把这个事放在心里，就算痛苦，也积极想办法，努力去做好。如果真是做到了，我们就可以跟自己说，不用遗憾。你可能会说，但是我当时有一段时间效率低，浪费时间了，这很遗憾啊！我回答道，你做的很好了，人不是机器，都有情绪，效率低也可以看作情绪积累的结果，低效率的你没有自暴自弃，所以可以坦然对待考研这个事情，要从中吸取经验教训，但不必再参杂过多苦涩，遗憾的情感。 ","date":"2021-03-25","objectID":"/3%E6%9C%8825%E6%97%A5%E6%80%BB%E7%BB%93/:0:0","tags":["思考"],"title":"3月25日总结","uri":"/3%E6%9C%8825%E6%97%A5%E6%80%BB%E7%BB%93/"},{"categories":["思考"],"content":"24号放松了一天，今天这些话是25号补充来的，想起之前有些思考比较好，但没有整理出来，故写于此。 考研出门那天，知道了结果后，我瘫坐在椅子上，脑子里不断浮现去年自己偏激思想：1、微积分没用，积个球体积，积个阴影面积，这有什么用？2、政治考试这东西，死记有什么用？3、他居然背代码，这东西不是理解的吗？之后仿佛意识到了什么，哦，原来自己是这么傲慢，我甚至有政治分可以少点，用专业课来补的想法，何等的傲慢？回学校之后跟别人聊了很多，别人也大都观察到了我的变化，但实际说变了可能不太严谨，应该是把内心想法放大了，想想大学为什么逃课，我一直都向往所谓的自由，但这是自由吗？不考虑后果的随心所欲就是自由吗？我想，自由应该是用一定的“不自由”换得的，有舍有得，用一年的努力换得三年相对工作而言的自由即读研。想多了，总之做事多想想后果，想想其残酷也好，困难也好，目的是让自己慎重对待每一个选择。 A-\u003eB-\u003eC可能我们推导的根基A就是错误的，我们怎么可能最终得到正确的判断呢？所以要不断怀疑自己的观点，因为我们是通过眼睛，耳朵，鼻子感受世界的，就好比色盲人眼中的世界是不一样的，不同人眼中的世界不同，所以没有人有绝对客观的观点，在这种情况下，多参考别人的意见就能很大程度修正我们的主管臆想，可能我臆想了一半，他臆想了一半，我们一交流，刚好把各自臆想的部分修正了，大家都变得相对客观。 ","date":"2021-03-24","objectID":"/3%E6%9C%8824%E6%97%A5%E6%80%BB%E7%BB%93/:0:0","tags":["思考"],"title":"3月24日总结","uri":"/3%E6%9C%8824%E6%97%A5%E6%80%BB%E7%BB%93/"},{"categories":["2021思考"],"content":"周杰伦的作品是很走心的，他投入了自己的心血，所以成功可看做是天时地利人和，首先作品质量过硬是根基，之后机遇，推广，风口就可遇不可求了，所以我们做事情也要保证自己做到第一条作品质量过硬，至于其他机遇呢，就不过多奢求了。 还有一点，发现就算是这么有才华的周杰伦也需要一个团队，方文山，吴宗宪，黄俊郎，和几位编曲的大师，所以，社交可以说是一种能力，即所谓虽然我不会，但我能找人做出来，在这个结果论的社会，还是颇具价值。 中午进行了华为的三面，主管面，屏幕里出现一个严肃的男人，一副道貌岸然的面孔，仿佛写着我到这个地位什么都有了，你现在有什么，你的命运掌握在我的手里，对面还不断传来嘈杂的声音，一下兴致全无，还是坚持说完，他毫无波澜，就好像对世上所有事物都不感兴趣似的，一直板着脸，对我的项目丝毫不关心，问我做项目遇到最大的困难，还问我人生中最大的挫折，我仔细想了想，回答了，从一开始，他们所做的一切都与他们的初衷背道而驰，当然当时时间紧促，没能组织好这么精炼的语言，但我想这会让我感到极大的挫败感，他追问我说，具体是什么，我说最近的考研失败，我们人是渺小的，很多事情我们掌控不了，现在想想可能答非所问了，但当时已经陷入了失败中，好嘛，看来面试不过还是很合理的，最后谈谈自己，以为自己心里很强大，能冷静接受失败和挫折，但仔细想想，这岂不又是一种傲慢？我作为一个平凡的人，何来这等优越感？这几天换做谁也不会一下就振作，我只是要安排好时间，别误了事就行，情绪低落了，就承认，不用故作乐观，做个悲观主义者又何妨？自己不是常说嘛，消极，是为了走更长的路，最近给自己放个假，玩玩游戏，看看书。 ","date":"2021-03-23","objectID":"/3%E6%9C%8823%E6%97%A5%E6%80%BB%E7%BB%93/:0:0","tags":["思考"],"title":"3月23日总结","uri":"/3%E6%9C%8823%E6%97%A5%E6%80%BB%E7%BB%93/"},{"categories":["2021思考"],"content":"今天和阿宁学长交流了关于二战的事情，最开始接触阿宁学长还是2019年下半年，那时候跟学长在南校操场踢过球，觉得学长踢的挺好，挺不苟言笑的，可谁能想到他是背负着考研的任务和当时“轻松”的我们踢球的呢？去年有见到了学长，已经考完研上岸了，轮到我考研了，学长不是个善于表达的人，大有传统父亲寡言沉默的感觉，但简单几句沟通就能感受到学长内心对生活，对家庭的热爱，仿佛在学长身上就没有抱怨两个字，我很欣赏这种乐观的心态，我没怎么体会过乐观看待事物的感觉，因为总是把事情往不好的方向考虑，这点自愧不如。 问了学长工作一年回来考研的原因，是因为在国企工作枯燥无味，且没有技术提升，所以6月毅然裸辞，回到长沙租房子准备考研，虽然学长只是寥寥几句，但仔细想想其中蕴藏了多少勇气和魄力，大有一种直挂云帆济沧海的气势，有些气节往往体现在一个普通的决定。学长是个善于做计划，执行计划的人，安定下来就开始按计划执行，每周保持踢球运动，他说这是他考研期间最快乐的时间，仔细想想有些后悔19年跟学长踢球时没观察他脸上的表情。学长身上有一种泰然处事，顺其自然的哲学，学习就认真学，踢球就尽情踢球，到什么人生阶段就做什么事情，太遥远模糊的事情也不过多烦恼。总是戴着帽子，然后比较平和的穿行在校园里，总能在各种运动中看到他的影子。 逻辑比较混乱，只记录了跟学长交流的自己感受。 ","date":"2021-03-22","objectID":"/3%E6%9C%8822%E6%97%A5%E6%80%BB%E7%BB%93/:0:0","tags":["思考"],"title":"3月22日总结","uri":"/3%E6%9C%8822%E6%97%A5%E6%80%BB%E7%BB%93/"},{"categories":["思考"],"content":"阿德勒心理学关于人的行为方面和心理方面都提出了相当明确的目标。 行为方面的目标有以下两点： ①自立。 ②与社会和谐共处。 支撑这种行为的心理方面的目标也有以下两点： ①”我有能力“的意识。 ②”人人都是我的伙伴“的意识。 《被讨厌的勇气》之读书笔记 - 慧保典的文章 - 知乎 https://zhuanlan.zhihu.com/p/108334434 一，人生不是与他人的比赛 阿德勒心理学反对一切纵向关系，提倡把所有的人际关系都看作横向关系。 不与任何人竞争，只要自己不断前进即可。当然，也没必要把自己和别人比较 健全的自卑感不是来自与别人的比较，而是来自与“理想的自己”的比较 无论走在前面还是后面都没有关系，我们都走在一个并不存在的水平面上，我们不断向前迈进并不是为了与谁竞争。价值在于不断超越自我。 一旦从竞争的怪圈中解放出来，就再没有必要战胜任何人了，也就能够摆脱“或许会输”的恐惧心理了，变得能够真心祝福他人的幸福，并能够为他人的幸福做出积极的贡献。 二，课题分离 课题分离是人际关系的出发点。我们必须从“这是谁的课题”这一观点出发，把自己的课题与别人的课题分离开来。基本上，一切人际关系矛盾都起因于对别人的课题妄加干涉，或者自己的课题被别人妄加干涉。所以遇到人际关系问题，首先要思考一下这是谁的课题，然后进行课题分离，哪些是自己的课题，哪些是别人的课题，要冷静的划清界限，不去干涉别人的课题，也不让别人干涉自己的课题。 即使父母也得放下孩子的课题，孩子不是为了满足父母的期待而活。 三，人际关系的终极目标 人际关系的终极目标，把对自己的执着变成对他人的关心。对别人寄予关心，建立横向关系，使用鼓励法，这些都能够带给自己“我对别人有用”这一实际感受，继而就能增加生活的勇气。 不能进行课题分离，一位拘泥于认可欲求的人，也是极其以自我为中心的人。认可欲求的实质——他人如何关注自己、如何评价自己、又在多大程度上满足自己的欲求？受这种认可欲求束缚的人，看似在看着他人，但实际上眼里却只有自己。失去了对他人的关心，而只关心“我”，也就是以自我为中心。 关于共同体的感觉，即便很难做到，阿德勒的回答是这样的：必须得有人开始，即使他人不合作，那也跟你没关系。 四，横向关系 如果你与某人建立起了纵向关系，那你就会不自觉的从纵向去把握所有的关系。如果能够与某个人建立起横向关系，也就是建立起真正意义上的平等关系的话，那就是生活方式的重大转变，以此为突破口，所有的人际关系都会朝着横向发展。 横向关系并不是说，任何人都能变成朋友，或者像对待朋友一样去对待每一个人，重要的是意识上的平等以及坚持自己应有的主张。 五，怎样活出真实的自我 1，自我接纳 “受自我意识羁绊，不能无拘无束行动”的问题，这可能是很多人都有的烦恼。那么我们再回到原点去看看，你的目的是什么、想要通过小心翼翼的行动获得什么呢？” “为了不被嘲笑，不被小瞧” “也就是说对本真的自己没有信心？所以才尽量避免在人际关系中展露本真的自己。一个人在房间里的时候，也一定能够放声歌唱，随着音乐起舞或者是高谈阔论吧” 有这种状况怎么办呢？首先从自我接纳开始。接纳真实的自己。什么是接纳自己？说的更明白一些，对得了60分的自己说，这次只是运气不好，真正的自己能得100分，这是自我肯定；与此相对，在诚实的接受60分的自己的基础上努力思考“如何才能接近100分”，这就是自我接纳。 2，他者信赖 无条件的相信别人。 如果一味的担心被背叛，那也只会关注到因此受到的伤害，但是如果不敢去信赖别人，那最终就会与任何人都建立不了深厚的关系。那么克服对背叛的恐惧感的勇气从哪里来呢？ ——自我接纳，只要能够接受真实的自己并看清自己能做到的，和自己做不到的，也就可以理解，背叛是他人的课题，继而也就不难迈出向他者信赖的步伐了。 3，他者奉献（提供价值，贡献感） 工作的本质是对他人的贡献。我们通过劳动不仅是赚钱，更是实现他者贡献，参与共同体，体会我对他人有用，进而获得自己的存在价值。 非常重要的一点，这里所说的他者贡献也可以是看不见的贡献。判断你的贡献是否起作用的，不是你，那是他人的课题，是你无法干涉的问题。是否真正做出了贡献，从原理上根本无从了解。也就是说，进行他者贡献时候的我们即使做出看不见的贡献，只要能够产生“我对他人有用”的主观感觉即“贡献感”也可以。 自我接纳、他者信赖、他者贡献，这三者是缺一不可的整体。正因为接受了真实的自我——也就是自我接纳（知道自己能做的，和做不到的）——才能够不惧背叛的做到他者信赖；而且正因为对他人给予无条件的信赖，并能够使他人为自己的伙伴，才能够做到他者贡献；同时正因为对他人有所贡献，才能够体会到“我对他人有用”，进而接受真实的自己，做到自我接纳。 六，活在此时此刻 人生不是一条线，而是成点的连续。 人生就像是在每一个瞬间不停旋转起舞的连续的刹那。在舞蹈中跳舞本身就是目的，最终会跳到哪里谁也不知道，当然作为跳的结果最终会到达某个地方，因为一直在跳动，所以不会停在原地，但是并不存在目的地。 想要到达目的地的人生可以称为潜在性的人生，与此相对，像跳舞一样的人生则可以称为现实性的人生。 把潜在性人生比喻为登山，可以这么来理解：如果登山的目的是登上山顶，那么它就是潜在性的行为，说得极端点，乘坐电梯登上山顶，逗留5分钟，然后再乘回电梯回来也可以。当然如果没能到达山顶的话，登山活动就等于失败。但是如果登山的目的不是登顶而是登山本身，那就可以说是现实性的活动，最终能不能登上山顶都没有关系。 人生中最大的谎言就是不活在“此时此刻”。纠结过去、关注未来，把微弱而模糊的光打下人生整体，自认为看到了些什么。甩开人生的谎言，毫不畏惧地把强烈的聚光灯打向“此时此刻”，我们可以做到。 人生很简单，并不是什么深刻的事情，如果认真的过好了每一个刹那，就没有什么必要令其过于深刻。 ","date":"2021-03-21","objectID":"/%E8%A2%AB%E8%AE%A8%E5%8E%8C%E7%9A%84%E5%8B%87%E6%B0%94/:0:0","tags":["思考"],"title":"被讨厌的勇气","uri":"/%E8%A2%AB%E8%AE%A8%E5%8E%8C%E7%9A%84%E5%8B%87%E6%B0%94/"},{"categories":["心理学"],"content":"低阶、中阶、高阶的INTJ分别是怎么样的？ - 沉香的回答 - 知乎 https://www.zhihu.com/question/394452710/answer/1732110212 我认为划分低阶、中阶、高阶intj的标准是与社会的交互方式。 ","date":"2021-03-21","objectID":"/intj%E5%88%92%E5%88%86/:0:0","tags":["心理学"],"title":"INTJ划分","uri":"/intj%E5%88%92%E5%88%86/"},{"categories":["心理学"],"content":"低阶intj intj对自我天然有着明确的认知，低阶intj同样，但此时低阶intj对自己在世界中的位置，或者社会中的自己是什么样没有清楚的认识，表现为狂妄自大，不屑真正去认识和接受这个社会的运作规律，不屑因为社会中的他人而改变自己的行为方式，不屑收敛自己对丑陋社会的厌恶、对他人的鄙夷和蔑视的态度，经常将“这个人是傻逼”直接写在脸上。 ","date":"2021-03-21","objectID":"/intj%E5%88%92%E5%88%86/:1:0","tags":["心理学"],"title":"INTJ划分","uri":"/intj%E5%88%92%E5%88%86/"},{"categories":["心理学"],"content":"中阶intj 中阶intj会认识到自己狂妄的态度并不利于实现目标或终极理想。这一阶段，intj开始探索自己与社会的交互，试图就“如何在这个社会中实现自己的目标”给出答案，包括真正开始对社会的运作规律形成自己的认识，如何利用这一规律实现自己的目标，自己该进行什么改变、以什么样的方式与社会的交互可以达到最小阻力（减少阻碍）和最大收益以实现自己的目的。这一阶段的intj对更高阶的intj尤为关注，因为此时intj可以通过他们已经形成的社会交互认识和决策来完善自己。intj对世界、社会、人类、自我、情感的观念在这一阶段会以更快的速度不断变化完善。而intj也将不断通过实践探索何种方式是最佳的与社会交互的方式，此时intj会变得更加谦卑，更多地模拟其他人格，也可能反复出现对自己、对自己的世界观等种种观念怀疑的情况，与低阶intj对自己人格非常自信的态度形成对比。 ","date":"2021-03-21","objectID":"/intj%E5%88%92%E5%88%86/:2:0","tags":["心理学"],"title":"INTJ划分","uri":"/intj%E5%88%92%E5%88%86/"},{"categories":["心理学"],"content":"高阶intj 高阶intj将重回对自己人格自信的态度，这种自信的态度建立在中阶时对世界、社会、自我不断修正后所得到的完善成熟的观念，建立在中阶时通过思考和实践总结形成的最佳与社会交互的方式，此时，高阶的intj应当已在他人看来有所成就，并因为自我观念的完善和世俗的成就，intj对其他人格的模拟程度和时间会降低，在如何与社会交互时以最小阻碍、最大收益以及如何能够展现真正的自我（intj不喜欢伪装，伪装只是权宜之计）实现平衡。 我不认为intj存在最终的完全完美的形态，到某一阶段就停止发展，呈现完美的状态。多数intj都以完美为目标，但intj会一直处于不断发展不断完善的状态。intj有着无穷发展完善的空间。 ","date":"2021-03-21","objectID":"/intj%E5%88%92%E5%88%86/:3:0","tags":["心理学"],"title":"INTJ划分","uri":"/intj%E5%88%92%E5%88%86/"},{"categories":["读书笔记"],"content":" 一个人对痛苦的感受能力和对无聊的感受能力成反比，这是由一个人的精神能力的大小所决定的。也就是说，一个人精神的迟钝一般是和感觉的迟钝和缺乏兴奋密切相关的，因此，精神迟钝的人也就较少感受到各种强度不一的痛苦和要求。但是，精神迟钝的后果就是内在的空虚。这种空虚烙在了无数人的脸上。并且，人们对于外在世界发生的各种事情——甚至最微不足道的事情——所表现出的一刻不停的、强烈的关注，也暴露出他们的这种内在空虚。人的内在空虚就是无聊的真正根源，它无时无刻不在寻求外在刺激，试图借助某事某物使他们的精神和情绪活动起来。 人们在这个世界上要么选择独处，要么选择庸俗，除此以外再没有更多别的选择了。 无论身在何处，我们只能在我们自身寻找或者获得幸福 无论在任何年龄阶段，一个人的自身拥有都是真正的和唯一持久的幸福源泉。我们这个世界乏善可陈，到处充斥着匮乏和痛苦，对于那些侥幸逃过匮乏和痛苦的人们来说，无聊却正在每个角落等待着他们。 我们之所以感到不满，原因就在于我们不断试图提高我们的要求，但同时，其他妨碍我们成功的条件因素却保持不变。 我们在这世上时日不多，不值得在可鄙的坏蛋的脚下爬行。 骂他人的人表明自己无法拿出被谩骂者的真正、确实的过错；否则，他就会把这些作为前提交代出来，然后充满信心地把结论留给他的听众去完成。但他却不是这样做。他提供了结论，但却说不出前提。他只能托词说这样做只是为了简便。 正如一个旅行者只有在抵达了一处高地以后，才能够回头总体、联贯地看到自己所走过的迂回曲折的道路，同样，只有当我们度过了生命中的一段时间，或者在我们的整体生命终结的时候，我们才能把我们的做事、业绩和创作的作品真正联系起来，包括其中确切的因果关联，甚至才能了解到它们的价值。只要我们仍然置身其中，那么我们的行事就只能总是遵循我们那固定不变的性格构成，受着动机的左右和我们能力的制约。由此可见，我们的行事自始至终都有其必然性，我们在每一刻都做着我们在那一刻认为合理和适当的事情。只有事后的结果才让我们看清到底发生了什么事；对事情整体的回顾才使我们明白事情的如何和为什么。 人生智慧的重要一点就是在关注现在和计划将来这两者之间达致恰到好处的平衡，这样，现在与将来才不至于互相干扰。许多人太过沉迷于现在，这些是无忧无虑、漫不经心的人；也有的人则更多地活在将来，他们则是谨小慎微、忧心忡忡的杞人。人们很少能够在处理现在和将来两者当中把握一个恰到好处的尺度。 无论事情多么悲痛，我们必须让过去的事情成为过去，或许我们难以做到这一点，但我们必须降伏我们的乖僻心情。——荷马 要过一种深思熟虑的生活，并且能从生活经验中汲取一切有益的教训，我们就必须勤于反省，经常回顾做过的事情和曾经有过的感觉和体验；此外，还要把我们以前对事情的判断和现在的看法，以前订下的计划及追求和最终得到的结果及满足互相比较。这是为获得人生经验所做的单独的反复温习。一个人的生活经历可被视为一本书的正文，而对生活经历的咀嚼和认识则是对正文做出的解释。如果一个人有太多的反省和认识，但生活经历却又很少，那就好比只有两行正文，但注解却有四十行之多。如果一个人阅历很广，但却对此甚少反省，获得的认识又不多，这样，就好比一种比邦迪那版丛书——里面没有注解，正文的许多意思都不甚了了。 首先，生活在社交人群当中必然要求人们相互迁就和忍让；因此，人们聚会的场面越大，就越容易变得枯燥乏味。只有当一个人独处的时候，他才可以完全成为自己。谁要是不热爱独处，那他也就是不热爱自由，因为只有当一个人独处的时候，他才是自由的。拘谨、掣肘不可避免地伴随着社交聚会。社交聚会要求人们做出牺牲，而一个人越具备独特的个性，那他就越难做出这样的牺牲。因此，一个人逃避、忍受抑[136]或喜爱独处是和这一个人自身具备的价值恰成比例。因为在独处的时候，一个可怜虫就会感受到自己的全部可怜之处，而一个具有丰富思想的人只会感觉到自己丰富的思想。一言以蔽之：一个人只会感觉到自己的自身。进一步而言，一个人在大自然的级别中所处的位置越高，那他就越孤独，这是根本的，同时也是必然的。 完全、真正的内心平和和感觉宁静——这是在这尘世间仅次于健康的至高无上的恩物——也只有在一个人孤身独处[138的时候才可觅到；而要长期保持这一心境，则只有深居简出才行。 因为孤独是幸福、安乐的源泉。据此可知，只有那些依靠自己，能从一切事物当中体会到自身的人才是处境最妙的人。所以，西塞罗说过，“一个完全依靠自己，一切称得上属于他的东西都存在于他的自身的人是不可能不幸福的。” 一个人的自身拥有越多，那么，别人能够给予他的也就越少。正是这一自身充足的感觉使具有内在丰富价值的人不愿为了与他人的交往而作出必需的、显而易见的牺牲；他们更不可能会主动寻求这些交往而否定自我。相比之下，由于欠缺自身内在，平庸的人喜好与人交往，喜欢迁就别人。这是因为他们忍受别人要比忍受他们自己来得更加容易。此外，在这世上，真正具备价值的东西并不会受到人们的注意，受人注意的东西却往往缺乏价值。每一个有价值的、出类拔萃的人都宁愿引退归隐——这就是上述事实的证明和结果。 一个人对社会交往的热衷程度大致上与他的精神思想的价值成反比。 孤独为一个精神禀赋优异的人带来双重的好处：第一，他可以与自己为伴；第二，他用不着和别人在一起。第二点弥足珍贵，尤其我们还记得社会交往所意味着的束缚、烦扰甚至危险，拉布叶说过：“我们承受所有不幸皆因我们无法独处”。热衷于与人交往其实是一种相当危险的倾向，因为我们与之打交道的大部分人道德欠缺、智力呆滞或者反常。不喜交际其实就是不稀罕这些人。一个人如果自身具备足够的内涵，以致根本没有与别人交往的需要，那确实是一大幸事；因为几乎所有的痛苦都来自于与人交往，我们平静的心境——它对我们的幸福的重要性仅次于健康——会随时因为与人交往而受到破坏。没有足够的独处生活，我们也就不可能获得平静的心境。 孤独是困苦的；但可不要变得庸俗；因为这样，你就会发现[146]到处都是一片沙漠。 如果一个人出于对别人的有理由的厌恶，迫于畏惧而选择了孤独的生活，那么，对于孤独生活的晦暗一面他是无法长时间忍受的，尤其正当年轻的时候。我给予这种人的建议就是养成这样的习惯：把部分的孤独带进社会人群中去，学会在人群中保持一定程度上的孤独。这样，他就要学会不要把自己随时随地的想法马上告诉别人；另外，对别人所说的话千万不要太过当真。他不能对别人有太多的期待，无论在道德上抑或在思想上。对于别人的看法，他应锻炼出一副淡漠、无动于衷的态度，因为这是培养值得称道的宽容的一个最切实可行的手段。虽然生活在众人之中，但他不可以完全成为众人的一分子；他与众人应该保持一种尽量客观的联系。这样会使他避免与社会人群有太过紧密的联系，这也就保护自己免遭别人的中伤和侮辱。 从这种意义上说，我们可以把社会人群比喻为一堆火，明智的人在取暖的时候懂得与火保持一段距离，而不会像傻瓜那样太过靠近火堆；后者在灼伤自己以后，就一头扎进寒冷的孤独之中，大声地抱怨那灼人的火苗。 对于我们遭遇的每一桩不幸，我们都难辞其咎——至少在某种程度上是这样——并不是在每种情况下都绝对真实，虽然在大多数情况下事实的确如此。正因为人们对此真理有所感觉，所以，人们才尽最大可能地遮掩和粉饰自己遭遇到的不幸，并且竭力装出一副若无其事的样子：他们担心别人从他们的不幸遭遇推断出他们的罪责。 因此，对任何关乎我们痛苦和快乐的事情都应该以理性和判断力去观察和考虑，那也就是进行冷静的、不掺带个人情绪的思考，运用纯粹的概念在抽象中操作。我们不应该让思考掺杂着想象，因为想象没有能力对事情作出判断。相反，想象只会带来扰乱我们情绪的清晰图像，陡增我们的痛苦，而不会有任何好处。 要留意那严肃的时光，因为它甚少来临。——歌德 参与修建一座建筑物的工人，并不会知道这座建筑物的总体规则；或者，他们不会在心里时刻记住这一规划。同样，一个人在度过生命中每一小时，每一天的时候，对于自己的总体生命进程及其特征也不甚了解。一个人的修改越独特、越具有价值和意义，那么，他就越有必要不时地认清自己生命总体发展的大致脉络和自己的计划，这对他大有好处。为此目的，他当然要踏上“认识自己”[7]的第一步，亦即了解清楚自己的首要和真正的意愿——这些对于他的幸福而言是至为重要的东西；然后，对于何者排在第二和第三位置必须心中有数。同时，他也应该大致上明白自己应该从事何种职业、需要扮演何种角色以及自己与这一世界的关系。如果一个人具备非凡的个性，那么，对自己的生命计划有一个大概的了解，能够比任[128]何一切都更有效地增强自己的勇气，振作、鼓足信心，激励自己行动起来，避免走进弯路。 但是，不管怎么[182]样，我们不应为此感到泄气，不要以为抽象的准则和格言无法指引我们的生活行为，因而放任自己。一切把理论性的规则应用于实际当中的工作都碰到同样的情况。首要的事情是明白和理解规律准则，其次则是具体学会应用这些准则。前者我们运用理性一次性就能做好；后者则需要我们进行循环渐进的练习。 在这里，我想对一切造作的行为发出警告：造作的行为总会引起别人的鄙视。首先是因为它造假和欺骗，这样，它就是懦弱的行径，因为欺骗源自于恐惧；其次，造作是我们对自己的某种自我谴责和贬低，因为我们试图显示出一副我们认为比自己更好、但我们其实又不是的样子。精心打扮，假装具有某种的素质，其实就是承认自己并不具备这样的素质。不管一个人是冒充拥有勇气、机智、学问、智慧、抑或吹牛以显得情场得意、有钱、有地位或任何其他，我们都可以从这种假冒行为得出结论：这个人正是在这一方面有所欠缺，因为如果我们真的拥有这方面的素质和长处，那我们并不会想到故意去显示、炫耀它——想到我们的这一","date":"2021-03-21","objectID":"/%E4%BA%BA%E7%94%9F%E7%9A%84%E6%99%BA%E6%85%A7/:0:0","tags":["思考"],"title":"人生的智慧","uri":"/%E4%BA%BA%E7%94%9F%E7%9A%84%E6%99%BA%E6%85%A7/"},{"categories":["2021思考"],"content":"考研失败的事实已经接受了，本就是学过概率论的人，对概率这套可以说是再熟悉不过了，但在看到自己过校线的时候，心里还是那么激动，今年进复试确实是小概率事件，看到复试线时候还能平静面试也说明自己心里早就接受这个事实了，残酷吗，不残酷吗，都说不上，只是遗憾，但遗憾吗，仅凭去年不成熟的自己，就算再来一次，就能成功了吗，自怨自艾，自暴自弃，很正常，但我已经逐渐成熟了，我要利用4月之前的这十天，充分规划自己的人生，去实践，去了解，去探索，消除自己所有的假设，跟刘晴老师探讨读博士这条路，看看走过来的人对读博的看法，还有就是路上遇到的困难，跟宁哥探讨一下，自己不成熟的地方，看看跟那些成功的人身上有哪些自身不具备的品质，最后就是自己了，这十天可能不会是满负荷，闲暇时间多看一些书，很多时候我们困囿于一些烦恼之中无法脱身，很大程度因为我们想不清楚，就像王小波写的一只特立独行的猪，他在那个不思考的社会，自身看书思考解决了自己很多困惑，所以我们多读书的道理就在其中，饱读书的智者往往是波澜不惊的，他们对世界，社会，自身的思考非常通透，引用钢之炼金术师中的一句话，一即全，全即一，我们自身都和烧瓶小人，贪婪等人造人很像，盲目去追求一些东西，很少去思考我们真正想要的东西是什么，最后要么在生命结束的一瞬想通满足，要么无疾而终。人生短暂，没有很多时间去探索，这就要求我们每天都尽力去思考，即使痛苦，即使越想越迷惑，但这是人生的首要问题，即方向选对了，走的再慢也是在向终点靠近。 多看书，多思考，多实践。 ","date":"2021-03-21","objectID":"/3%E6%9C%8821%E6%97%A5%E6%80%BB%E7%BB%93/:0:0","tags":["思考"],"title":"3月21日总结","uri":"/3%E6%9C%8821%E6%97%A5%E6%80%BB%E7%BB%93/"},{"categories":["2021思考"],"content":"INTJ 的痛苦来源于哪里，又应该怎样解决? https://www.zhihu.com/question/389163913/answer/1417576579 《你不懂我，我不怪你》 每个人都有一个死角， 自己走不出来，别人也闯不进去。 我把最深沉的秘密放在那里。 你不懂我，我不怪你。 每个人都有一道伤口， 或深或浅，盖上布，以为不存在。 我把最殷红的鲜血涂在那里。 你不懂我，我不怪你。 每个人都有一场爱恋， 用心、用情、用力，感动也感伤。 我把最炙热的心情藏在那里。 你不懂我，我不怪你。 每个人都有一行眼泪， 喝下的冰冷的水，酝酿成的热泪。 我把最心酸的委屈汇在那里。 你不懂我，我不怪你。 每个人都有一段告白， 忐忑、不安，却饱含真心和勇气。 我把最抒情的语言用在那里。 你不懂我，我不怪你。 你永远也看不见我最爱你的时候， 因为我只有在看不见你的时候，才最爱你。 同样， 你永远也看不见我最寂寞的时候， 因为我只有在你看不见我的时候，我才最寂寞。 也许，我太会隐藏自己的悲伤。 也许，我太会安慰自己的伤痕。 也许，你眼中的我，太会照顾自己， 所以，你从不考虑我的感受。 你以为，我可以很迅速的恢复过来，有些自私的以为。 从阴雨走到艳阳，我路过泥泞、路过风。 一路走来，你不曾懂我，我亦不曾怪你。 我不是为了显示自己的大度， 也不是为了体现自己的大方。 只想让你知道，感情不在，责备也不存在。 ","date":"2021-03-04","objectID":"/3%E6%9C%884%E6%97%A5%E6%80%BB%E7%BB%93/:0:0","tags":["思考"],"title":"3月4日总结","uri":"/3%E6%9C%884%E6%97%A5%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"全自动的彩色眼底图像分割是自动化的眼底疾病筛查系统和辅助诊断系统的基础，能大大改善传统眼底疾病筛查和诊断的流程，降低眼科医生的阅片的工作量，优化医疗资源的配置。眼底图像中常见的结构包括血管、视盘和视杯，对于眼疾患者，可能还存在病灶，如渗出、微动脉瘤等。结构的形态变化以及病灶的有无、病灶的面积和数量等是眼疾诊断的重要临床依据。 眼底图像分割方法是语义分割方法在分析眼底图像中的具体应用。语义分割可以表述为带有语义标签的像素分类问题，其对图像所有像素使用一组对象类别（如人、车、树、天空）进行像素级标记，因此通常比预测整个图像隶属单个标签的图像分类困难。本文总结了现有的基于深度学习的语义分割方法，介绍常用数据集，网络架构，损失函数等。 Fully automatic color fundus image segmentation is the basis of the automated fundus disease screening system and auxiliary diagnosis system, which can greatly improve the traditional fundus disease screening and diagnosis process, reduce the workload of ophthalmologists, and optimize the allocation of medical resources . Common structures in fundus images include blood vessels, optic discs, and optic cups. For patients with eye diseases, there may be lesions such as exudation and microaneurysms. The morphological changes of the structure, the presence or absence of lesions, the area and number of lesions, etc. are important clinical evidence for the diagnosis of eye diseases. Fundus image segmentation method is the specific application of semantic segmentation method in analyzing fundus image. Semantic segmentation can be expressed as a pixel classification problem with semantic labels, which uses a set of object categories (such as people, cars, trees, and sky) to mark all pixels of the image at the pixel level. Therefore, it is usually more difficult than predicting that the entire image belongs to a single label. This article summarizes the existing semantic segmentation methods, introduces commonly used data sets, network architectures, loss functions, etc. 绪论 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:0:0","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"研究背景与意义 视网膜血管网络是唯一可以在体内可视化和拍照的血管系统。视网膜血管成像能够为患有特定心血管疾病和眼科疾病的患者提供临床预后信息.当前，视网膜血管分割高度依赖于经验丰富的眼科医生的手工工作，这是繁琐，耗时且可再现性低的。因此，迫切需要一种全自动且准确的视网膜血管分割方法，以减少眼科医生的工作量，并提供客观，精确的视网膜血管异常测量。有几个因素使这项任务具有挑战性。血管的长度和口径因对象而异。血管，血管边界，视盘和中央凹等各种病变的存在（包括出血，渗出液，微动脉瘤和纤维化带）可与血管混淆。此外，血管的相对低的对比度和一些眼底图像的低质量进一步增加了分割难度。视网膜是人类眼球后部的所谓眼底。眼底图像中有许多小血管，唯一可以无创地直接观察到的是人体深部血管。与年龄相关的黄斑变性，还有其他一些眼部疾病也与高血压，动脉粥样硬化和糖尿病等疾病密切相关。分割血管并从眼底图像中提取血管特征，使得医生可以快速诊断和确定病情并提高诊断效率，这是非常重要的。 青光眼是目前发病率率最高的视神经疾病之一，截至目前，全世界的青光眼患者的人数已经达到七千万以上。青光眼是由眼内压升高而引起的视神经纤维损伤所致，这是一种不可逆的损伤，没有自愈的可能。并且青光眼术后失明率也是非常之高。青光眼早期是没有明显的症状的，但随着疾病的进展，患者会逐渐失去视力。等到出现视力不佳且难以识别的患者去医院就诊，往往已进入青光眼末期，此时视神经纤维很可能已经严重受损且难以康复。中国是世界上青光眼患者最多的国家，所以研究开发一种可以自动诊断识别青光眼的医疗系统迫在眉睫。杯盘比指的是视杯直径与视盘直径之比。通常来说，正常眼底的杯盘比值为0.3 至 0.5。如果杯盘比值超过了0.5，则怀疑患者有可能是青光眼。所以使用人工智能算法实现自动进行视杯视盘分割具有重要意义。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:1:0","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"语义分割方法总结 学术界已经有了很多成熟的图像分割方法，从最早的直方图阈值化方法，特征空间聚类方法，区域增长方法和SVM及随机森林等机器学习方法等，到近年卷积神经网络的兴起，衍生出了大量创新性的工作，包括全卷积网络，编码器-解码器结构，多尺度提取特征和基于金字塔的方法，递归神经网络，视觉注意力模型，以及生成对抗模型等。 眼底图像分割方法研究课题分析 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:2:0","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"视杯和视盘分割 青光眼是一种慢性眼病，会使视神经退化，导致视杯(OC)与视盘(OD)之间的比率很大。在临床上，杯盘比(CDR)是由专业眼科医生手动估计的。这是耗费体力和时间的。为了使准确的彩色多普勒血流图的定量自动化，并辅助青光眼的诊断，OD和OC的分割越来越受到重视。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:3:0","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"血管分割 眼球底部的视网膜血管是全身血管系统中唯一可以无创直接观测到的部分, 其自身的变化, 例如血管宽度、角度、分支形态等, 均可作为与血管相关疾病的诊断依据。眼科致盲疾病, 例如青光眼、糖尿病视网膜病变、老年性黄斑病变等, 能直接从眼底视网膜血管病变中观察到。 深度学习背景下的语义分割方法综述 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:4:0","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"术语及背景知识 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:5:0","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"语义分割 语义分割是对一张图像进行像素级的分类。由于语义分割问题被定义为像素级，意味着仅仅是图像的分类是不够的，还需要在原图像上进行以像素级的分辨率进行定位。 更加正式的明确语义分割任务如下： 输入： $R^{H \\times W \\times 3}$ 常规的图片，其中H和W分别代表输入图片的高和宽。 输出： $R^{H \\times W \\times classNum}$ classNum为给定的数据集的类别数，也就是一共classNum个通道的H*W大小的特征图。每一个通道对应一 class,对每一个像素位置，都有classNum个通道,每个通道的值对应那个像素属于该class的预测概率。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:5:1","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"卷积神经网络 卷积神经网络（Convolutional Neural Network）主要由三部分组成： 1.卷积层，使用卷积核（或滤波器）提取特征。 2.非线性层，在特征图上（通常是逐元素地）应用激活函数，以便通过神经网络对非线性函数进行建模。 3.池化层，池化层用一些统计数据替换了特征图的小范围邻域（平均值，最大值等），降低空间分辨率。 每个单元都从前一层中较小的邻域（称为感受野）接收加权输入。通过堆叠层数以形成多分辨率金字塔， 高层可以从越来越宽的感受野中学习特征。 CNN的主要计算优势在于，同层的卷积核相同，共享权重，因此与完全连接的神经网络相比，参数数量明显减少。一些最著名的CNN架构包括：AlexNet，VGGNet，ResNet，GoogLeNet和MobileNet。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:5:2","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"RNN和LSTM RNN被广泛用于处理顺序数据，例如语音，文本，视频和时间序列，其中任何给定时间或位置的数据都取决于先前遇到的数据。在每个时间戳上，模型都会收集当前时间$\\mathop X\\nolimits_i$的输入和上一步$\\mathop h\\nolimits_{i - 1}$的隐藏状态， 并输出目标值和新的隐藏状态。RNN通常在长序列方面存在问题，因为在许多实际应用中它们无法捕获长期依赖关系（尽管它们在这方面没有任何理论上的限制），并且经常遭受梯度消失或爆炸问题的困扰。长短时记忆网络旨在避免这些问题。LSTM体系结构包括三个门（输入门，输出门，遗忘门），通过门控状态来控制传输状态，记住需要长时间记忆的，忘记不重要的信息。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:5:3","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"编码器-解码器和自编码器模型 由编码函数编码器-解码器模型是一组模型，可以学习通过两级网络将数据从输入域映射到输出域：由编码函数 $z = f(x)$ 表示的编码器将输入压缩为潜在空间表示；解码器 $y = g(z)$旨在预测潜在空间表示的输出。这里的潜在表示本质上是指特征（矢量）表示，它能够捕获底层的输入的语义信息，可用于预测输出。这些模型在图像到图像的翻译问题以及NLP中的序列模型中非常流行。重建损失用于测量ground-truth $y$和后续重建$\\hat{y}$之间的差异。通常通过最小化重建损失$L(y, \\hat{y})$来训练这些模型。此处的输出可以是图像的增强版本（例如，在图像去模糊或超分辨率中）。自编码器是编码器-解码器模型的特例，其中输入和输出相同。最受欢迎的一种是堆叠式降噪自编码器（SDAE），它可以堆叠多个自编码器并将其用于图像降噪。另一个流行的变体是变体自编码器（VAE），它在潜在表示上施加了先验分布。VAE能够根据给定的数据分布生成实际样本。对抗性自动编码器是另一种变体，它在潜在表示上引入对抗性损失，以使它们近似先验分布。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:5:4","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"Transformer Transformer有一个编码器-解码器结构。编码器由六个相同的层组成，每层有两个子层:一个多头自注意力模块和一个简单的全连接前馈网络。如图所示，在每一层之后，使用残差连接和层标准化。注意，不同于同时执行特征聚集和特征变换的常规卷积网络(例如，卷积层之后是非线性)，这两个步骤在Transformer模型中是解耦的，即自注意力层仅执行聚集，而前馈层执行变换。与编码器类似，Transformer模型中的解码器包含六个相同的层。每个解码器层有三个子层，前两个子层(多头自注意力和前馈)类似于编码器，而第三子层对相应编码器层的输出执行多头注意力。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:5:5","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"迁移学习 在某些情况下，可以在新的数据集上从头开始训练深度学习模型（假设有足够数量的已标记训练数据），但是在许多情况下，没有足够的已标记数据来从头开始训练模型，可以使用迁移学习解决这个问题。在迁移学习中，经过对新任务的适应，将在一个任务上训练的模型重新用于另一相关任务。例如，可以使在ImageNet上训练的图像分类模型适应不同的任务，例如纹理分类或面部识别。在语义分割的情况下，许多人使用在ImageNet上训练的模型（比大多数图像分割数据集更大的数据集）作为网络的编码器部分，并从这些初始权重中重新训练他们的模型。预训练的模型应该能够捕获分割所需图像的语义信息，因此能够用较少已标记样本来训练模型。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:5:6","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"数据集 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:6:0","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"STARE(structured snalysis of the retinal) STARE 是 1975 年由 Michael Goldbaum 发起的项目, 它在 2000 年由 Hoover等首次在论文中引用并公开，是用来进行视网膜血管分割的彩色眼底图数据库,包括 20 幅眼底图像, 其中 10 幅有病变, 10 幅没有病变, 图像分辨率为 605×700, 每幅图像对应 2 个专家手动分割的结果,是最常用的眼底图标准库之一.。但是其自身的数据库中没有掩膜，需要自己手动设置掩膜。目前它已扩展到40 幅血管分割手工标注结果和 80 幅视神经检测手工标注结果。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:6:1","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"DRIVE(digital retinal images for vessel extraction) DRIVE是 Niemeijer 团队在 2004年根据荷兰糖尿病视网膜病变筛查工作建立的彩色眼底图库。 其图像是从 453 名 25 90 岁的不同个体拍摄得到,随机抽取了其中 40 幅, 其中 7幅是有早期糖尿病视网膜病变的, 33 幅是没有糖尿病视网膜病变的眼底图,每幅图像的像素为 565×584. 分成训练集和测试集, 每个子集 20 幅图像,每幅图像对应 2个专家手动分割的结果.其自身有专门的掩膜，调用方便。比较好的运用到监督学习和深度学习的图像训练当中。该库是衡量视网膜血管分割方法性能好坏的最常用数据库。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:6:2","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"IDRiD(Indian Diabetic Retinopathy Image Dataset) IDRiD的图像是由位于印度的一家眼科诊所的视网膜专家拍摄的。从数以千计的有效检测中，提取了516张图像来构成数据集。专家证实，所有图像均具有足够的质量，临床相关性，没有图像重复并且存在糖尿病视网膜病变（DR）和糖尿病黄斑水肿（DME）的疾病分层的合理混合。它是唯一一个由典型糖尿病视网膜病变和正常视网膜结构组成的数据集。该数据集提供关于糖尿病视网膜病的疾病严重程度以及每张图像的糖尿病黄斑水肿情况。数据集具体由81个带有DR标记的彩色眼底图像组成。提供与DR相关的异常的精确像素级注释，例如微动脉（MA），软性渗出（SE），硬性渗出（EX）和出血（HE）的二值化掩膜，用于评估单个病变分割技术的性能。它包括彩色眼底图像（.jpg文件）和由病变组成的二值化掩码（.tif文件）。除了所有异常图像之外，还提供了所有81张图片的视杯视盘区域的二值化掩膜。根据国际临床糖尿病视网膜病变量表，将糖尿病视网膜图像分为不同的组。黄斑水肿的严重程度是根据在斑点中心区域附近出现的硬分泌物而决定的。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:6:3","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"OIA(Ophthalmic Image Analysis) OIA-DDR数据集和OIA-ODIR数据集是OIA系列数据集的两个子集。其中，OIA-DDR数据集包含13673张眼底图像，包含了四种糖尿病视网膜病变相关的病变点的标注，757张包含像素级和bounding-box级的病变点标注。OIA-ODIR数据集包含10000张眼底图像，取样人群年龄涵盖全年龄段人群，其中30周岁至80周岁的人群占比超过96%；该数据主要针对眼部多疾病同步诊断，每张眼底图像包含8个疾病标签，分别为：正常N、糖网病D、青光眼G、白内障C、老年黄斑变性A、高血压H、近视M、其他疾病/异常O。OIA-ODIR数据集是基于一张眼底图像的多类型病变检测数据集。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:6:4","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"REFUGE(Retinal Fundus Glaucoma Challenge) REFUGE公布了1200张针对青光眼的眼底彩色图像数据，评估和比较数据集上的青光眼检测、视盘/杯分割及黄斑中心凹定位的自动算法。该数据库是目前青光眼眼底照片精标数据库中最全面的标注数据库，主要包括青光眼与非青光眼两种类型数据，其中青光眼和非青光眼图像的比例分别为10% 和90%。每张眼底图像分别包含诊断、图像分割及定位三方面信息，由七位专家人工标记并融合，克服了之前许多青光眼公开数据集存在的只有诊断标签信息，无视杯、视盘等关键结构的标注信息，且参与标注的专家较少等缺点。所有图像均以后极（postserior pole）为中心，同时含有黄斑和视盘。在这个数据集中，由训练集、验证集和测试集三个组成。训练集中有400 张像素为 2142 × 2056 的眼底图像，是使用 Zeiss Visucam 500眼底相机拍摄的，而验证集和测试集各由 400 张像素均为 1 634 × 1634的眼底图像组成，是使用 Canon CR-2 眼底相机拍摄的。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:6:5","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"评价指标 对于k+1类（k个前景类和背景类），其中$\\mathop p\\nolimits_{ij}$是类别i的像素被预测为类别j的像素数。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:7:0","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"Pixel Accuracy (PA) 分类正确的像素点数和所有像素点数的比例。 $$PA = \\frac{{\\sum\\nolimits_{i = 0}^k {\\mathop p\\nolimits_{ii} } }}{{\\sum\\nolimits_{i = 0}^k {\\sum\\nolimits_{j = 0}^k {\\mathop p\\nolimits_{ij} } } }}$$ ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:7:1","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"Mean Pixel Accuracy (MPA) 逐类计算正确分类像素和所有像素点数比例，然后求平均。 $$MPA = \\frac{1}{{k + 1}}\\sum\\limits_{i = 0}^k {\\frac{{\\mathop p\\nolimits_{ii} }}{{\\sum\\nolimits_{j = 0}^k {\\mathop p\\nolimits_{ij} } }}}$$ ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:7:2","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"Intersection over Union (IoU) or the Jaccard Index 预测分割图和真实分割图之间的交集面积与并集面积之比。 $$IoU = J(A,B) = \\frac{{|A \\cap B|}}{{|A \\cup B|}}$$ ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:7:3","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"Mean-IoU 所有类别的平均IoU $$MIoU = \\frac{1}{{k + 1}}\\sum\\limits_{i = 0}^k {\\frac{{\\mathop p\\nolimits_{ii} }}{{\\sum\\nolimits_{j = 0}^k {\\mathop p\\nolimits_{ij} + } \\sum\\nolimits_{j = 0}^k {\\mathop p\\nolimits_{ji} } - \\mathop p\\nolimits_{ii} }}}$$ ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:7:4","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"Precision/Recall/F1 score TP表示真阳性分数，FP表示假阳性分数，FN表示假阳性分数，FN表示假阴性分数。 $$Precision = \\frac{{TP}}{{TP + FP}}, Recall = \\frac{{TP}}{{TP + FN}}$$ F1分数是准确率和召回率的调和平均数。 $$F1 - score = \\frac{{2\\Pr ec{\\mathop{\\rm Re}\\nolimits} c}}{{prec + {\\mathop{\\rm Re}\\nolimits} c}}$$ ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:7:5","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"Dice coefficient 预测分割图和真实分割图的重叠区域的两倍与两分割图中像素的总数和之比。Dice系数和IoU呈正相关关系 $$Dice = \\frac{{2|A \\cap B|}}{{|A| + |B|}}$$ ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:7:6","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"语义分割模型 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:0","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"FCN 1.全卷积 通常CNN网络在卷积池化之后会接上若干个全连接层，将产生的特征图映射成为一个固定长度的特征向量。一般的CNN结构适用于图像级别的分类和回归任务，因为它们最后都期望得到输入图像属于各个类别的概率。FCN对图像进行像素级的分类，从而解决了语义级别的细粒度图像分割问题。与经典的CNN在卷积层后加全连接层得到固定长度的特征向量进行分类不同，FCN可以接受任意尺寸的输入图像，采用反卷积对最后的特征图进行上采样，使它恢复到输入图像相同的尺寸，从而可以对每一个像素都产生一个预测。全卷积网络从抽象的特征中恢复出每个像素所属的类别。即从图像级别的分类进一步延伸到像素级别的分类。 2.跳层连接 语义分割任务包括语义识别和目标定位两个方面。通常经过CNN多次卷积池化后得到的高层特征图可以反映抽象语义信息，低级特征图可以精确反映位置信息。权衡二者，使用跳层连接，将低层位置信息丰富的特征图和高层和高层语义信息丰富的特征图融合，提高语义分割性能。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:1","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"U-Net U-Net网络常用于医学图像分割。 1. U型对称结构。左侧为收缩路径即编码器，经过多次卷积池化缩小特征图，以提取高级语义特征，右侧是扩张路径即解码器，经过多次转置卷积扩大特征图，以将特征图解码还原成原图大小进行像素级分类。 2. U-Net网络的每个卷积层得到的特征图都会融合到对应的上采样层，从而实现每层特征图都有效使用到后续计算中，即跳层连接。U-Net结合了低级特征图和高级特征图，提高模型的结果精确度。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:2","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"Deeplab（V1 V2 V3 V3+） DeepLabv1 是由深度卷积神经网络和概率图模型级联而成的语义分割模型，由于深度卷积神经网络在重复下采样的过程中会丢失很多的细节信息，所以采用扩张卷积算法增加感受野以获得更多上下文信息，增大感受野可间接减少层数。使用全连接条件随机场来提高模型捕获细节的能力。 DeepLabv2 增加了 ASPP（Atrous spatial pyramid pooling）结构，利用多个不同采样率的扩张卷积提取特征，再将特征融合以捕获多尺度的上下文信息。 DeepLabv3 在 ASPP中加入了全局平均池化，同时在扩张卷积后添加批量归一化，有效地捕获了全局语境信息。 DeepLabv3+ 在 DeepLabv3 的基础上增加了编-解码模块和 Xception主干网络，增加编解码模块主要是为了恢复原始的像素信息，使得分割的细节信息能够更好的保留，同时编码丰富的上下文信息。增加Xception主干网络是为了采用深度卷积进一步提高算法的精度和速度。在inception结构中，先对输入进行1*1的卷积，之后将通道分组，分别使用不同的3*3卷积提取特征，最后将各组结果串联在一起作为输出。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:3","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"RefineNet RefineNet可以分为两部分，分别对应于U-Net中收缩（下采样提取语义特征）和扩张（上采样恢复细节信息）两段路径。收缩路径使用ResNet。扩张路径使用RefineNet，其得到的特征与ResNet中低级特征的融合。 RefineNet可以分为三个主要部分： 1.不同尺度的特征输入首先经过两个残差卷积单元处理。 2.不同尺度的特征进行融合。所有特征上采样恢复分辨率，然后进行加和。 3.最后经过链式残差池化模块。思想是分支上的卷积池化用于提取高级语义信息或者说背景上下文信息，与输入加和以达到融合高级语义信息和低级位置信息。最后再经过一个残差卷积单元即得RefineNet的输出。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:4","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"PSPNet 1.全局平均池化，替代全连接层，减少参数同时增加了先验知识以达到正则化的效果。 2.金字塔池化，生成的不同尺度的特征图最终被上采样恢复原图大小拼接起来，然后进行卷积调整通道数，进行Softmax分类。金字塔池化模块能收集不同尺度的语境信息并融合，会比全局池化所得的全局信息保留更多细节。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:5","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"GCN GCN全局卷积网络从两个设计原则出发： 1. 定位角度，使用全卷积结构，保留更多位置信息。 2. 分类角度，使用大尺寸卷积核，以达到在输入尺寸改变时保持感受野足够大。 GCN模块，卷积核的大小和各个尺度的特征图大小相同以提取全局信息，为了减少参数数量用，k x 1和1 x k两次卷积代替一次k x k卷积，1 x k 和 k x 1两次卷积代替一次1 x 1卷积，并且没有非线性操作。 BR模块，使用残差结构细化边界。 整体网络架构： 使用预训练的ResNet作为特征提取网络，FCN4作为分割框架，从特征提取网络的不同阶段提取多尺度的特征图，后接GCN模块用于生成每个类的多尺度语义分数图，BR模块用于细化边界。使用转置卷积对分辨率较低的分数图进行上采样，然后与分辨率较高的分数图相加，以生成新的分数图，在最后一次上采样后，生成语义分数图，用于输出预测结果。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:6","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"EncNet 之前引入全局上下文信息的方法大致有两个，扩张卷积和金字塔结构，但这两种方法都一定程度上割裂了单个像素和整个图像的关系。如果能够先捕获图像上下文信息(例如这是卧室)，然后，就可以根据背景语义缩小分类范围 (例如卧室里面有床、椅子等)，以动态的减少搜索范围。或者说，加入对于场景的先验知识，这样对图片中像素分类更有针对性。 EncNet使用上下文编码模块捕获图像全局信息，结合上下文信息给每个通道的特征图加权，以达到利用全局信息进行分割的效果。同时集成了语义编码损失（SE-loss）。一般方法逐像素计算交叉熵损失，不考虑全局上下文信息，SE-loss在编码层之上添加了一个带Sigmoid激活的全连接层单独用于预测场景中出现的类别，并计算二分类交叉熵损失，减少了图像中出现的类别噪声。不同于逐像素计算损失训练集大物体的像素数多于小物体，SE-loss 考虑大小不同的物体有相同的贡献，这能够提升小目标的检测性能。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:7","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"NonLocal Net 扩大感受野利用全局信息对语义分割很有帮助，全连接完整利用了全局信息，但是增加了大量参数，难以训练，卷积操作利用空间不变性减少了参数数量，但是只能利用局部信息，NonLocal Net利用注意力机制，每次计算都使用全部像素，同时计算相似度函数对其加权。这样既利用了全局信息又使网络容易训练。 $$\\mathop y\\nolimits_i = \\frac{1}{{C(x)}}\\sum\\limits_{\\forall j} {f(\\mathop x\\nolimits_i ,\\mathop x\\nolimits_j )g(\\mathop x\\nolimits_j )}$$ ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:8","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"PSANet 和NonLocal Net思想相同，主要区别如下： 1.有两个分支学习双向关系，分别起到collect和distribute的作用。 2.相关度矩阵$f$的计算。对于像素$i$，其相关度向量$f({x_i},x)$，通过施加在${x_i}$上的两个1 x 1卷积得到，即由$f({x_i},x)$ 变为$f({x_i})$，只和query和相对位置相关。 此外，PSANet包含两路attention，相当于Transformer中的两个head。两路分别起到collect和distribute的作用。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:9","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"DANet 和NonLocal Net思想相同，主要区别如下： 1. 使用双分支，分别是位置注意力机制和通道注意力机制方法。 2. 使用残差机制。 具体结构和Transformer相同。B，C，D矩阵分别对应Transformer中的Q，K，V。 $${s_{ji}} = \\frac{{\\exp ({B_i} \\cdot {C_j})}}{{\\sum\\nolimits_{i = 1}^N {\\exp ({B_i} \\cdot {C_j})} }}$$ $${E_j} = \\alpha \\sum\\limits_{i = 1}^N {({s_{ji}}{D_i}) + {A_j}}$$ $${x_{ji}} = \\frac{{\\exp ({A_i} \\cdot {A_j})}}{{\\sum\\nolimits_{i = 1}^C {\\exp ({A_i} \\cdot {A_j})} }}$$ $${E_j} = \\beta \\sum\\limits_{i = 1}^C {({x_{ji}}{A_i}) + {A_j}}$$ ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:10","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"CCNet 和NonLocal Net思想相同，主要区别如下： 将NonLocal Net中的${(H * W)^2}$次计算像素点之间的相似性简化成两次迭代计算当前像素点和同行同列的像素点之间的相似性，共${(H * W) *(H + W - 1)}$次计算，提升了计算效率。 {width=“0.5\\linewidth”} ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:11","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"APCNet 整体流程描述如下： 原始图片先经过CNN得到特征图，后接多个提取不同尺度特征ACM模块和原特征图结合组成最终特征图，后接卷积调整通道数量，最后预测结果。 ACM模块具体描述如下： ACM模块有两个分支组成，上面的分支用于计算亲和系数，亲和参数为单一尺度下h*w个像素对应s*2大小的贡献度权重矩阵，下面的分支用于提取单一尺度的特征图，最后将信和系数与特征图做矩阵乘法得到最终用于预测的特征图。 第一个分支先经过1*1卷积调整通道数为512即降维，之后做全局平均池化提取全局信息，与降维后得到的特征图相加，即使每个像素结合全局信息，再用1*1卷积降维成s*s个通道，最后reshape成hw*s*s的亲和系数矩阵。 第二个分支先经过自适应池化调整成s*s大小，后接1*1卷积调整通道数为512即初步得到s*s*512特征图，再和上面分支得到的亲和系数矩阵做矩阵乘法得到hw*512的特征图，最后采用了残差的思想将最终的特征图与1*1卷积后得到的h*w*512特征图相加最终得到了在s尺度下的特征表示。 总结: 1.利用了多尺度信息，即使用多个s值不同的ACM模块最后整合。 2.计算亲和系数矩阵前，每个像素整合了全局信息，所以使得到的亲和系数矩阵既有单个像素信息也有全局像素信息，以达到表示单个像素和全局像素相关性的效果。 3.引入注意力机制，即计算亲和系数矩阵。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:12","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"SENet $Ftr$是传统的卷积结构，X和U是$Ftr$的输入$(C' \\cdot H' \\cdot W')$和输出$(C \\cdot H \\cdot W)$，SENet增加的部分是U后的结构，即对U先做全局平均池化，输出1*1*C的向量后接两个全连接层，最后加Sigmoid函数将范围限制在0，1之间，把这个值作为放缩系数与对应通道相乘。 总结: 增加了有Squeeze压缩和Extraction解压两部分的分支用于得到放缩系数，把重要的通道增强，不重要的通道减弱，以实现注意力机制。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:13","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"GCNet 基于NonLocalNet和SENet，结合两者优点提出了GCNet，计算量相对较小，又能很好地融合全局信息。 NonLocal Net公式如下： $${z_i} = {x_i} + {W_z}\\sum\\limits_{j = 1}^{{N_p}} {\\frac{{f({x_i},{x_j})}}{{C(x)}}} ({W_v} \\cdot {x_j})$$ 对其中的attention map $\\frac{{f({x_i},{x_j})}}{{C(x)}}$ 可视化如下： 作者发现训练好的NonLocal Net中，对于图像中不同位置计算的attention map几乎一致。所以，作者对NonLocal Net进行了简化，通过计算一个全局的attention map来简化non-local block，并且对所有位置共享这个全局attention map。忽略 ${W_z}$，简化版的non-local block定义为： $${z_i} = {x_i} + \\sum\\limits_{j = 1}^{{N_p}} {\\frac{{\\exp ({W_k}{x_j})}}{{\\sum\\nolimits_{m = 1}^{{N_p}} {\\exp ({W_k}{x_m})} }}} ({W_v} \\cdot {x_j})$$ 为了进一步z减少简化版non-local block的计算量，将 ${W_v}$ 移到attention pooling的外面，表示为： $${z_i} = {x_i} + {W_v}\\sum\\limits_{j = 1}^{{N_p}} {\\frac{{\\exp ({W_k}{x_j})}}{{\\sum\\nolimits_{m = 1}^{{N_p}} {\\exp ({W_k}{x_m})} }}} {x_j}$$ 其结构如下： {width=“0.3\\linewidth”} 由于Transform结构中有大量参数，为了获得SENet轻量化的特点，1x1卷积用bottleneck transform模块替代，能显著降低参数量，思路即使用C x C/r，C/r x C/r和 C/r x C三次变换替代C x C一次变换，参数数量从C x C缩减为2 x C x C/r + C/r x C/r。因为两层bottleneck transform增加了优化难度，所以在ReLU前面增加一个layer normalization层。 最后GCNet结构如下： {width=“0.3\\linewidth”} ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:14","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"DMNet DCM模块具体如下： 第一个分支执行1 x 1卷积调整通道数为512，得到降维后特征图。 第二个分支先执行自适应池化将原图调整为k x k大小，后接1 x 1卷积调整通道数512，得到降维后卷积核，与降维后特征图进行卷积。 总结：特点是Context-aware filters使类似PSPNet的金字塔池化，将图片划分k x k个区域，使用多个k值不同的DCM模块即可达到多尺度信息融合，后接1 x 1卷积结果不做常规的特征图，而是作为卷积核，和上面分支得到的特征图进行卷积操作，个人理解相当于卷积核结合特征图信息进行了有意义的初始化，有利于卷积核参数的训练。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:15","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"ParseNet 为了整合全局信息，设计两条分支。 第一条分支先进行全局池化，平均池化或者最大池化，得到1 x 1 x C的特征向量，之后经过L2归一化，后接反池化恢复原特征图尺寸。 第二条分支对每一个像素位置的1 x 1 x C向量进行L2归一化，最后与第一条分支结果结合。 总结:利用简单的全局平均池化保留每个通道的特征图的全局信息，后接L2归一化。L2归一化的目的是消除量纲大小对特征选择的影响，防止出现在进行特征选择时，偏向数值大的特征，忽视数值小的特征。最后反池化以恢复原特征图尺寸，与经L2归一化的特征图结合得到最终特征。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:16","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"OCRNet 主要思想是显式地把像素分类问题转化成物体区域分类问题，这与语义分割问题的原始定义是一致的，即每一个像素的类别就是该像素属于的物体的类别，换言之，与PSPNet 和 DeepLabv3 的上下文信息最主要的不同就在于 OCR方法显式地增强了物体信息。假设backbone输出特征维度是b x c x h x w，共有k个类别。 OCR 方法的实现主要包括3个阶段： 1.根据网络中间层的特征表示估测一个粗略的语义分割结果作为 OCR方法的一个输入 ，即软物体区域（Soft Object Regions），具体是后接1 x 1卷积调整通道数，得到b x k x h x w的输出。 2.根据粗略的语义分割结果和网络最深层的特征表示计算出 k组向量，即物体区域表示（Object Region Representations），其中每一个向量对应一个语义类别的特征表示（因为组略的语义分割结果包含了物体区域信息，相当于用每个物体区域的mask和像素特征表示做矩阵乘法），具体是b x c x h x w的Pixel Representations和 b x k x h x w 的转置做矩阵乘法得到b x k x c输出即Object Region Representations。 3.计算网络最深层输出的像素特征表示PR（Pixel Representations）与计算得到的物体区域特征表示ORR（Object Region Representation）之间的关系矩阵，然后根据每个像素和物体区域特征表示在关系矩阵中的数值把物体区域特征加权求和，得到最后的物体上下文特征表示 OCR (Object Contextual Representation) 。具体是b x k x c的ORR和b x c x h x w的PR做矩阵乘法得到b x k x h x w的输出，再在维度k加上Softmax函数转化为attention map同时也是解码器即PRR（Pixel-Region Relation），再对PRR和ORR做矩阵乘法得到b x c x h x w的OCR。当把物体上下文特征表示 OCR 与网络最深层输入的特征表示拼接之后作为上下文信息增强的特征表示（Augmented Representation），可以基于增强后的特征表示预测每个像素的语义类别。综上，OCR可计算一组物体区域的特征表达用于表示每一类物体的区域特征，然后根据物体区域特征表示与像素特征表示之间的相关性，得到结合物体区域特征的像素特征表示。 参考文献 Liu Q, Zou B, Zhao Y, et al. A Deep Gradient Boosting Network for Optic Disc and Cup Segmentation[C]//ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE,2020: 971-975. Kirbas C, Quek F A review of vessel extraction techniques and algorithms[J]. ACM Computing Surveys, 2004, 36(2): 81-121 Minaee S, Boykov Y, Porikli F, et al. Image segmentation using deep learning: A survey[J]. arXiv preprint arXiv:2001.05566, 2020. Long J, Shelhamer E, Darrell T. Fully convolutional networks for semantic segmentation[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2015: 3431-3440. Ronneberger O, Fischer P, Brox T. U-net: Convolutional networks for biomedical image segmentation[C]//International Conference on Medical image computing and computer-assisted intervention. Springer, Cham, 2015: 234-241. Chen L C, Papandreou G, Kokkinos I, et al. Semantic image segmentation with deep convolutional nets and fully connected crfs[J]. arXiv preprint arXiv:1412.7062, 2014. Chen L C, Papandreou G, Kokkinos I, et al. Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs[J]. IEEE transactions on pattern analysis and machine intelligence, 2017, 40(4): 834-848. Chen L C, Papandreou G, Schroff F, et al. Rethinking atrous convolution for semantic image segmentation[J]. arXiv preprint arXiv:1706.05587, 2017. Chen L C, Zhu Y, Papandreou G, et al. Encoder-decoder with atrous separable convolution for semantic image segmentation[C]//Proceedings of the European conference on computer vision (ECCV). 2018: 801-818. Lin G, Milan A, Shen C, et al. Refinenet: Multi-path refinement networks for high-resolution semantic segmentation[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 1925-1934. Zhao H, Shi J, Qi X, et al. Pyramid scene parsing network[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 2881-2890. Peng C, Zhang X, Yu G, et al. Large kernel matters–improve semantic segmentation by global convolutional network[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 4353-4361. Zhang H, Dana K, Shi J, et al. Context encoding for semantic segmentation[C]//Proceedings of the IEEE conference on Computer Vision and Pattern Recognition. 2018: 7151-7160. Wang X, Girshick R, Gupta A, et al. Non-local neural networks[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2018: 7794-7803. Zhao H, Zhang Y, Liu S, et al. Psanet: Point-wise spatial attention network for scene parsing[C]//Proceedings of the European Conference on Computer Vision (ECCV). 2018: 267-283. Fu J, Liu J, Tian H, et al. Dual attention network for scene segmentation[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019: 3146-3154","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:17","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["2021思考"],"content":"3月1日，从家回到了学校，虽然已经出成绩两天，依然没能走出失败的阴霾。是的，考研失败了，一次又一次的冲击着我的心，这就是现实，时间是单向的，我们无法掌控。人总有一个无谓的假象，如果回到当时没有做错事，现在会是什么结果。这当然是实现不了的，我们还是那么憧憬，因为遗憾，和不成熟。我到底什么时候能独当一面，我到底什么时候能泰然处世，我到底什么时候能成熟做事？无数的疑问涌上心头，难道我没有才能吗？难道我没有努力吗？难道我注定要经历失败？我的内心不堪重负，开始放空，开始逃避这些沉重的问题，渐渐的，我的心开始冰冷，不再有了当年的一腔热血，有了很多负面想法，我懒惰，我自负，我逃避，我又一次开始讨厌我自己，我一直以来到底在坚持什么？我所谓的坚持难道就只是我不想适应社会的借口吗？我的努力就一文不值吗？没有回答。 黑暗中的微光仿佛隐隐说到，行动起来啊，接受平凡的自己，踏实努力的往前走啊。 致大学中迷茫且什么也没做好的自己：就算痛苦，迷惘，失望，也要勇敢去做啊！ ","date":"2021-03-01","objectID":"/3%E6%9C%881%E6%97%A5%E6%80%BB%E7%BB%93/:0:0","tags":["思考"],"title":"3月1日总结","uri":"/3%E6%9C%881%E6%97%A5%E6%80%BB%E7%BB%93/"},{"categories":["2020思考"],"content":"狄时禹先走一步了，看起来是个短暂别离，但是谁知道这次别离有多久呢，我没有莫愁前路无知己，天下谁人不知君的洒脱，人生的别离再正常不过，我们很难很长一段时间都与一个朋友或几个朋友在一起相处，真的很难，有相遇就有别离，但不是对相遇感到失望，想着相遇就总要别离的嘛，那干嘛还那么认真对待每一次相遇呢，反而应该有一种正因直到自己的渺小，这段相遇可能不会很久，反而珍惜这段缘分，一起留下最美好的回忆。 ","date":"2020-11-22","objectID":"/11%E6%9C%8822%E6%97%A5%E6%80%BB%E7%BB%93/:0:0","tags":["思考"],"title":"11月22日总结","uri":"/11%E6%9C%8822%E6%97%A5%E6%80%BB%E7%BB%93/"},{"categories":["2020思考"],"content":"离考研还有35天。 要多提升专注力，才能记住东西，尽可能进入心流模式，这是唯一的途径了。 事情总是会比想象中的多，计划总是会被一些无缘无故的琐事干扰，自己总是不能全身心投入某一件事中。 这大概是大多数人面临的一个懊恼难题吧，特别是现在各种科技互联网移动设备的发展，好多有趣玩意儿正在不断分散我们的注意力，我们很难再集中注意力去完成一件事了（当然这怪不了人家互联网，这只是我们社会协作关系极度复杂化的结果）。 如何去做到集中注意力做一件事是呢？这的确成了一件很难做到的事， 首先、我们的时间在不断碎片化。 其次、我们有太多的事要同步运行，分同照料。 1、心流状态 “心流”是人们全身心投入某事的一种心理状态，心理学家米哈里·希斯赞特米哈伊(Mihaly Csikszentmihalyi)将心流 (flow) 定义为一种将个人精神力完全投注在某种活动上的感觉；心流产生时同时会有高度的兴奋及充实感。 心流理论在创建初期提出的观点是：如果一个人的能力低于他做一件事情所需要的能力，他就会觉得太难了，感到焦虑；而如果能力高于这件事情所需要的能力，他又会觉得太简单了，感到无聊。只有当能力刚刚与挑战难度相等时，人既不会感到焦虑，也不会感到无聊，才会产生心流。只要达到这种心流状态，人就可以很容易集中注意完成某一项活动。 米哈里齐克森认为，使心流发生的活动有以下特征： 1.我们倾向去从事的活动。 2.我们会专注一致的活动。 3.有清楚目标的活动。 4.有立即回馈的活动。 5.我们对这项活动有主控感。 6.在从事活动时我们的忧虑感消失。 7.主观的时间感改变–例如可以从事很长 的时间而不感觉时间的消逝。 8.不断优化的障碍，我们对于所从事的活动是力所能及的，且具有一定挑战的，我们可以通过不断地练习来增加完成障碍的能力。 2、如何达到心流 找出对抗点。 心流不会凭空出现，我们必须主动寻求这种状态，这时便会出现对抗点。 你必须经过努力才能进入心流状态，必须对抗阻止我们进入心流状态的混乱和干扰因素，包括互联网、手机、游戏、以及不健康的人际关系等。有太多因素会分散我们的注意力，我们需要避开这些对抗点。 这里需要我们合理安排时间，包括工作时间，娱乐时间和社交时间，在规定的时间做应该做的事，像对待其他事情一样，安排你的心流时间。 断开联接，改变思维。 心流的一个关键先导因素是从紧张与压力中解脱出来，断开与当前活动不相关联接，对一项活动通常有四种情况分别是：重要且紧急的事，重要但不紧急的事，不重要但紧急的事，不重要也不紧急的事。 这里的轻重缓急全靠你个人衡量，但记住一次只考虑一件事，断开与其他事情的连联，让自己放松下来。 在这种情况下，我们会改变大脑的运行方式，改变神经化学状态，改变思维方式。只有这时候我们才能进入心流状态。 少些感慨，多些行动。 心流的本质——完全沉浸在眼下。如果你在担心过去或计划未来，便很难进入心流状态。通过设定明确的目标（“今天我想实现这个目标。”）和排除干扰，来提高自己进入心流状态的可能性。 落实行动，只有行动才能有结果，如果总是停留在思考和感慨上面，那只会增加你的心里压力；相反，通过行动可以获得及时的反馈，自己对于活动也会多一些主控感，自己很容易就可以进入心流状态。 注意休息，保持活力。 心流也会令人筋疲力尽。在心流状态中，我们的大脑会变得疯狂，身体中产生的神经化学物质将创造出高度专注、富有创造力、异常欣快的状态。 而这些神经化学物质减少之后，我们会出现一些不好的现象，比如怠惰，疲劳等。睡眠、阳光和营养非常重要，所以退出心流状态之后，到阳光下去散散步，然后好好休息一下或者吃顿好的。不要因为心流状态的结束而感到惋惜，要享受复原的过程。 你的大脑需要休息。放松心情，恢复精力。否则以后将很难重新回到心流状态，高强度学习不一定是高效率的学习，而劳逸结合才是高效学习的方法论。 重复练习，形成反射。 事实证明，我们进入心流状态的次数越多，就越容易进入其中。训练大脑进入和停留在心流状态的次数越多，进入心流状态也就越容易。 心流这种心理状态也像我们平时的习惯，重复的练习重复的体验，随着时间的推移，进入心流状态更容易。经常让自己达到心流状态，或者形成一种条件反射，那你就可以对心流状态进行主控，这样你就很容易全身心投入一件事中。 ","date":"2020-11-20","objectID":"/11%E6%9C%8820%E6%97%A5%E6%80%BB%E7%BB%93/:0:0","tags":["思考"],"title":"11月20日总结","uri":"/11%E6%9C%8820%E6%97%A5%E6%80%BB%E7%BB%93/"},{"categories":["2020思考"],"content":"2000年1月24日到今天，自己已经快要21岁了，人生不能一直低估，也该振作起来了，想想自己当初进学校斗志昂扬，自信满满，觉得自己什么都能做到，然而却困于自制力和自己封闭的思想，很多事情都没做好，现在考研是在让大学还算圆满，永远永远不要找借口，没做好就是没做好，不要想着做错了或者没做好还有人安慰，生而为人，没有人没有压力，每个人的笑脸下都隐藏着很多焦虑悲伤的负面情绪，那自己是不是也应该成熟了呢，难道一有负面情绪就跟家里父母诉苦吗，我真的已经21岁了吗？是因为我没有处理情绪的能力吗？还是我自己不想长大？还指望着有家长解决一切，过着无忧无虑的生活吗？ 什么叫对自己负责？ - warfalcon的回答 - 知乎 https://www.zhihu.com/question/43203505/answer/192578584 最好的方式是经过冷静、周全的思考之后做出决定。为这个选择承担一切后果，不管是好是坏，不后悔，这才是算对自己负责。 顺便举几个我自己的例子： 1 在20年前认识老婆，花了三年时间追到老婆，谈恋爱谈了三年，在做出结婚这个决定时之前，问自己三个问题并做出回答，确信已经能很冷静考虑结婚这件事： • 这个女人是否是我想要的另一半（是） • 我们俩的性格和脾气是否适合在一起过一辈（是） • 将来的某一天我是否会因为其它原因而后悔（不后悔） 在结婚之前，我妈对老婆不太满意，认为还能找到条件更好的。当时我跟老妈长谈了一次。忘了原话是怎么说的，大意如下： 在找老婆这件事上，不需要任何人代替我来做选择。就是再有一个条件更好的，那又能怎么样，我不喜欢。 你替我选老婆，选错了，你能承担后果吗，你怎么承担。是我跟她过一辈子，不是你。 换句话说，就是我选错了人，将来我们过不到一起时，我自己来承担所有一切后果，不会怨天尤人。我会为这个决定而负责。 后来，我妈看我态度坚定，而且跟老婆当时靠自己的能力在外面生活的还可以，就是阻拦，我也不会太在意，还会坚持这个决定，就同意了。 顺便说一句，当初在丈母娘眼中也同样没太中意我，丈母娘也跟老婆说过，老公是你自己选的，你可别后悔。 今年是婚后第十四年，我跟老婆都反思过多次这个问题：后悔当初的选择吗？ 不，从来没后悔过。要是时间可以倒流，我还会重复这个决定。 2 在10年前2007年8月初，开始写第一个Blog：战隼的学习探索。在初期做这事的时候，就是纯靠自己爱好。但时间长了，坚持写Blog是件很花精力和时间的事情。 身边的人，包括老婆、好友和同事都对这个事情不看好，都在这个事情说过我很多回，写这个东西有什么用。浪费这个时间，赚点钱好不好。写Blog，能当钱花吗？甚至有这个精力，多接几个私活，赚点钱好不好。 确实，在刚开始的几年里，我要是把写Blog的精力放在其它事情上，不管是赚钱、学习还是其它事情上，回报都会比写Blog更有帮助。在2009、2010年的时候，在网上认识的不少Bloger，也都开始放弃Blog转战微博或者直接放弃了。 在写到第四年的时候，也无非是一个月能得到100、200美元的广告费，以及参加一些活动时，有人跟我说一直在看我的Blog和偶尔能收到感谢的留言。 在这期间也花过时间仔细思考过这个问题，Blog还有必要写下去吗？ 在纸上列出优缺点的对比，写blog这事就是不能直接带来金钱上的好处，但在其它方面对我来说，还是有很多好处的，有必要坚持写下去。写不下去的时候，没有动力的时候，可以换种方式。后来在2011年，尝试了一整年的每天一本书。 从豆瓣转到知乎，又从知乎转到微信公众号，没想到，公众号发展这么快，竟然可以靠公众号赚钱，混口饭吃。 一直到今天，已经不知不觉写了快十年了。 怎么也想不到，因为坚持一个10年前的决定，能让我过上理想中的生活。 3 我自己并不是一个意志力很强的人，沉迷过漫画、小说、游戏，每一次都花不少的时间和精力。在沉迷游戏的时候，还考虑过是否要靠游戏赚钱。 主要是当时眼界太窄，不知道天高地厚，另外当时在中国靠游戏赚钱，生活的实在是过于艰难，才决定放弃。 等到后来大学时接私活，组装网吧电脑和网络时开始接触网络游戏–石器时代。当时思考了好几天，这个东西实在太好玩了，但按我的性格一旦玩上就会沉迷进去，在大学这个阶段，没有时间沉迷在游戏上，一定会误事，经过冷静思考之后，决定不玩网络游戏。 到现在回想起来都在庆幸这个决定，因为没玩网游，把精力花上学电脑和编程上，然后才有机会进入IT这行。当时跟我一起接私活的，还有一个朋友，结果就因为沉迷游戏，导致没法按时毕业，挂了好多科，后来家里给找了个工作，当了公务员。这人当时跟我的目标完全一样，好好学电脑，毕业之后，去北京或深圳闯一闯。因为沉迷游戏，人生的轨迹被改变。 除了这三个故事，在这些年做过不少重大决定，有跟所有人判断一致，也有周围人一致反对的，结果也有好有坏。经历多了慢慢发现，在决定时最主要一点是要真正想清楚自己想要的是什么，喜欢什么，反对什么。专门留出一段时间，最好是在经过充分休息后，冷静而周全的思考，然后再做决定。 特别是重大决定，应该尽可能跳出短期利弊，按三观进行选择。哪怕是选择错了，也不用后悔，承担自己的负责就好，这才是对自己负责。 而明明知道，某种行为对自己不利，还在随波逐流，自我欺骗的进行下去，就是对自己不负责。比如按父母亲属的意见结婚、过着自己不喜欢的生活、在人生的重要决定上放手、选择自己不喜欢的工作/职业、坚持了对自己不利的行为，任凭自己距离梦想越来越远。 你应该问问自己：我真的尽力了吗，在为自己负责吗？ 怎样才能变得自律 我们在此为大家提供“自律四部曲”，教你用各种轻量技巧达到自律效果： 明确目标 这并不意味着需要给自己设立一个宏大的目标，恰恰相反，我们需要仔细思考并了解自己，这是自律训练的第一步——帮助我们在做出行为反应的时候，进行内在冲动和长远目标的权衡和思考。 细化目标 将目标拆分成具体的执行方式，能够帮助我们认识到某些方式的重要性。另外，可视化目标也有利于我们训练自己的自律能力。我们通过想象的方式，将完成分期目标的每一个方式、步骤，而不仅仅是行动结果，在脑海中进行“可视化”。在此过程中，我们也会对每一种实现方式的重要性有更清晰的认知。 做出行动 尽管这个步骤无需过多的解释，但在实际生活中，这却往往是需要最多努力和自律的一步。 为每一小步庆祝 在完成每一个分期任务之后，我们需要庆祝自己取得的成就（哪怕很小）。一方面，庆祝作为一种完成任务后的仪式，是一种“延迟的满足”，这本身就是“自律”的一种培养和体现，同时也是对所付出努力的一种自我肯定。 最后总结一下：自律作为一种理智的主动选择，并不会为我们带来压抑欲望后的焦虑，而我们要做的只是明确目标，然后just do it！ ","date":"2020-11-04","objectID":"/11%E6%9C%884%E6%97%A5%E6%80%BB%E7%BB%93/:0:0","tags":["思考"],"title":"11月4日总结","uri":"/11%E6%9C%884%E6%97%A5%E6%80%BB%E7%BB%93/"},{"categories":["2020思考"],"content":"最近是十一假期，信息院球队的学长从五湖四海回到长沙，见到他们还是感到非常亲切，可能是分开的时间没有很长，对每个学长还是非常熟悉，见到他们更多的是一种很自然亲切的感觉，曹8，彤哥，大黄，凯哥，黄刈，大帝，椅子，还有17级和18级的大家，这两天晚上都参与了聚餐，其中有几个学长和学弟给我的印象非常深刻，首先是黄未名学长，以前一直以来给我的印象都是经常来踢球嘴人，一副玩世不恭的样子，但他酒桌上说的关于他那段考研经历的一席话给我很大的冲击，首先他一直强调他认识到他自己不是个聪明的人，这就带给我很大的震撼，在这个竞争意识非常普遍且强烈的社会，能放低自己，承认自己的不足是非常需要勇气而且难能可贵的，他能非常坦然的说出来，确实是非常成熟了。再者，黄学长说了他自己考研时每天的安排，一天学习14个小时，遇到不会的题，不慌，先用手机把题拍下来，等到吃饭或者休息的时候拿出来看看，想一想，再不会，晚上睡觉之前冥想回顾，并且要做到知其然并且知其所以然，他给我建议一定不要眼高手低，做题的时候一定要按照考试的标准认真把步骤写出来，做完对照答案仔细复盘哪一步错了，分析为什么错。反思自己有时候以智商稍高自居，其实这是自己不想努力的借口。之后就是黄学长的人生观非常通透，为什么用通透这个词，我发现从他的人生哲学中我感受到了他对人生和为人处世的思考，几句简单的话却非常有道理，1.就比如踢球，我把我的优点发挥出来嘛，尽量找到一个踢法减少暴露自己的缺点嘛，比如我速度慢，我就少带球嘛，拿球就传，不然别人知道我速度慢。再有就是他对足球和学习的态度，踢球是不影响学习的，没见过哪个人因为踢球导致学习不好的，他自己也确实是个证明，只要把时间安排好，该学习的时候就高效学习，那玩的时候就可以放纵的玩。本质上就是把时间安排好利用好。第二个印象深刻的人是彤哥，每每跟彤哥说话就总是有种莫名的感动，可能也是见到了很少的一些内心仍然保持着最初的那份单纯，即使经历了很多黑暗的事情，最后仍然能保留着一方净土，真的是很难能可贵的，包括曹博号也是重情义且单纯的人，彤哥说他是个理想主义者，诚然，他说好多次都梦见自己没赶上火车，他真的太想大家了，能感受到这份兄弟间的情谊，真的非常感动，男人之间的感情真的非常坚固，很多非常艰辛的困难都无法让一个男人落泪，而往往是兄弟间的一句关心问候，一个善意的帮助，就能轻易击穿内心的壁垒，流露出最柔软的内芯。我能想象到学长们毕业开始工作后，烦恼越来越多，发现大学的种种情谊是那么宝贵，凯哥也抽了烟，本就沉默寡言的凯哥现在更是多了几分愁容，更多时候就是坐在角落里默默抽着烟，彬才学长还是那么谦虚，对学弟也是非常照顾和尊敬，我一直觉得自己之前有点愧疚，没有表现得那么尊敬他。说回彤哥，彤哥说对自己还是有信心的，也衷心的希望我能考上研弥补自己的所谓的遗憾，他说，做到考完研，无论结果怎么样，对自己不会说后悔，我很多时候都深陷后悔和自责的泥潭，彤哥也希望我能少些自责，自己其实也做到了很多东西，他一直也说我来实验室的时运不太好，他希望我以后无论做什么事，把人的主观能动性发挥到最大，无论时运如何，把自己做到最好，不留遗憾。我想自己也应该尽全力去做些什么，无论结果如何，只想给自己一段回忆，每每想起来，心中充满的是充实和感动，就像大黄学长一样，可以跟学弟非常骄傲和自豪的说出来！ ","date":"2020-10-03","objectID":"/10%E6%9C%883%E6%97%A5%E6%80%BB%E7%BB%93/:0:0","tags":["思考"],"title":"10月3日总结","uri":"/10%E6%9C%883%E6%97%A5%E6%80%BB%E7%BB%93/"},{"categories":["2020思考"],"content":"今天，保研的一系列政策和名额出来了，狄时禹很大概率保研，我最开始了解到这个情况的时候是真心的为他感到高兴，因为他是我很好的朋友，我很认可他这个人和他做出的很多成果，我对自己本专业保研的人向来是不抱有多少羡慕的，很大程度上是因为自己的自我满足，总觉得自己多牛逼，做到了其他人做不到的事情，然后淡化了别人的成就，安慰自己说，看他虽然保研了，但是代码不会写，能力也不行，反观自己，却把很多自己没做到或者没做好的事情装作自己根本就没认真去做，这完全是一种弱者逃避，自我安慰的姿态，也不是说完全否定自己之前的想法，我总觉得年轻人要有一些狂气，带着一股闯劲去面对各种各样的机遇和挑战，但是我今天想强调的是什么，一定要多接受外界信息，万万不可自己各种想象感觉，大有唯心主义的意味，不得不说马克思主义对人生有很大的指导意义。再分析为什么今天一了解到狄时禹几乎保研，自己的心情会感到如此低落，甚至走在路上哭了出来，心情久久不能平复。首先，在我的内心深处，我一直把狄时禹不光认作朋友，还当成一个非常强的竞争对手。仔细想想，当成竞争对手就是把自己和别人放在同一个平台了，大有追赶和超越的意味。但是自己目前来讲能力是不及狄时禹的，这个也是直到今天他保研了，我才真正意识到自己的一点点成就是多么渺小。很多时候我都在吐槽自己的学校多么多么差，但是自己呢，学校里很多人都比我优秀太多，倒不是说大家智商差多少，把差距归因于智商是非常懦弱的行为，面对与强者的差距，应以客观冷静的态度应对，着重分析他是怎么做出很多成果的，而不是着眼于他的成就的多少。现在心情平静了很多，我作为一个普通人，大家大多数都是普通人，我们能做的只有努力和调整方法论，一个人想要进步，就要先承认自己的弱小，认清自己的定位，然后着眼于眼前的事情，一步一步踏实前进，这需要极大的自律和毅力，大多数人都没能坚持住，或是假装努力自我满足，辩证法告诉我们要辩证的看问题。我目前已经无需再探讨这些了，没什么意义，只是告诉自己去正视这些成就，没有人不劳而获。我能做的只有哦把握好每一天，积极努力，不断根据实际情况调整方法论，不设限，把自己的潜能挖掘出来，加油。 ","date":"2020-09-21","objectID":"/9%E6%9C%8821%E6%97%A5%E6%80%BB%E7%BB%93/:0:0","tags":["思考"],"title":"9月21日总结","uri":"/9%E6%9C%8821%E6%97%A5%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"中南大学本科生 ","date":"0001-01-01","objectID":"/about/:0:0","tags":null,"title":"About","uri":"/about/"}]