[{"categories":["思考"],"content":"阿德勒心理学关于人的行为方面和心理方面都提出了相当明确的目标。 行为方面的目标有以下两点： ①自立。 ②与社会和谐共处。 支撑这种行为的心理方面的目标也有以下两点： ①”我有能力“的意识。 ②”人人都是我的伙伴“的意识。 《被讨厌的勇气》之读书笔记 - 慧保典的文章 - 知乎 https://zhuanlan.zhihu.com/p/108334434 一，人生不是与他人的比赛 阿德勒心理学反对一切纵向关系，提倡把所有的人际关系都看作横向关系。 不与任何人竞争，只要自己不断前进即可。当然，也没必要把自己和别人比较 健全的自卑感不是来自与别人的比较，而是来自与“理想的自己”的比较 无论走在前面还是后面都没有关系，我们都走在一个并不存在的水平面上，我们不断向前迈进并不是为了与谁竞争。价值在于不断超越自我。 一旦从竞争的怪圈中解放出来，就再没有必要战胜任何人了，也就能够摆脱“或许会输”的恐惧心理了，变得能够真心祝福他人的幸福，并能够为他人的幸福做出积极的贡献。 二，课题分离 课题分离是人际关系的出发点。我们必须从“这是谁的课题”这一观点出发，把自己的课题与别人的课题分离开来。基本上，一切人际关系矛盾都起因于对别人的课题妄加干涉，或者自己的课题被别人妄加干涉。所以遇到人际关系问题，首先要思考一下这是谁的课题，然后进行课题分离，哪些是自己的课题，哪些是别人的课题，要冷静的划清界限，不去干涉别人的课题，也不让别人干涉自己的课题。 即使父母也得放下孩子的课题，孩子不是为了满足父母的期待而活。 三，人际关系的终极目标 **人际关系的终极目标，把对自己的执着变成对他人的关心。**对别人寄予关心，建立横向关系，使用鼓励法，这些都能够带给自己“我对别人有用”这一实际感受，继而就能增加生活的勇气。 不能进行课题分离，一位拘泥于认可欲求的人，也是极其以自我为中心的人。认可欲求的实质——他人如何关注自己、如何评价自己、又在多大程度上满足自己的欲求？受这种认可欲求束缚的人，看似在看着他人，但实际上眼里却只有自己。失去了对他人的关心，而只关心“我”，也就是以自我为中心。 关于共同体的感觉，即便很难做到，阿德勒的回答是这样的：必须得有人开始，即使他人不合作，那也跟你没关系。 四，横向关系 如果你与某人建立起了纵向关系，那你就会不自觉的从纵向去把握所有的关系。如果能够与某个人建立起横向关系，也就是建立起真正意义上的平等关系的话，那就是生活方式的重大转变，以此为突破口，所有的人际关系都会朝着横向发展。 横向关系并不是说，任何人都能变成朋友，或者像对待朋友一样去对待每一个人，重要的是意识上的平等以及坚持自己应有的主张。 五，怎样活出真实的自我 1，自我接纳 “受自我意识羁绊，不能无拘无束行动”的问题，这可能是很多人都有的烦恼。那么我们再回到原点去看看，你的目的是什么、想要通过小心翼翼的行动获得什么呢？” “为了不被嘲笑，不被小瞧” “也就是说对本真的自己没有信心？所以才尽量避免在人际关系中展露本真的自己。一个人在房间里的时候，也一定能够放声歌唱，随着音乐起舞或者是高谈阔论吧” 有这种状况怎么办呢？首先从自我接纳开始。接纳真实的自己。什么是接纳自己？说的更明白一些，对得了60分的自己说，这次只是运气不好，真正的自己能得100分，这是自我肯定；与此相对，在诚实的接受60分的自己的基础上努力思考“如何才能接近100分”，这就是自我接纳。 2，他者信赖 无条件的相信别人。 如果一味的担心被背叛，那也只会关注到因此受到的伤害，但是如果不敢去信赖别人，那最终就会与任何人都建立不了深厚的关系。那么克服对背叛的恐惧感的勇气从哪里来呢？ ——自我接纳，只要能够接受真实的自己并看清自己能做到的，和自己做不到的，也就可以理解，背叛是他人的课题，继而也就不难迈出向他者信赖的步伐了。 3，他者奉献（提供价值，贡献感） 工作的本质是对他人的贡献。我们通过劳动不仅是赚钱，更是实现他者贡献，参与共同体，体会我对他人有用，进而获得自己的存在价值。 非常重要的一点，这里所说的他者贡献也可以是看不见的贡献。判断你的贡献是否起作用的，不是你，那是他人的课题，是你无法干涉的问题。是否真正做出了贡献，从原理上根本无从了解。也就是说，进行他者贡献时候的我们即使做出看不见的贡献，只要能够产生“我对他人有用”的主观感觉即“贡献感”也可以。 自我接纳、他者信赖、他者贡献，这三者是缺一不可的整体。正因为接受了真实的自我——也就是自我接纳（知道自己能做的，和做不到的）——才能够不惧背叛的做到他者信赖；而且正因为对他人给予无条件的信赖，并能够使他人为自己的伙伴，才能够做到他者贡献；同时正因为对他人有所贡献，才能够体会到“我对他人有用”，进而接受真实的自己，做到自我接纳。 六，活在此时此刻 人生不是一条线，而是成点的连续。 人生就像是在每一个瞬间不停旋转起舞的连续的刹那。在舞蹈中跳舞本身就是目的，最终会跳到哪里谁也不知道，当然作为跳的结果最终会到达某个地方，因为一直在跳动，所以不会停在原地，但是并不存在目的地。 想要到达目的地的人生可以称为潜在性的人生，与此相对，像跳舞一样的人生则可以称为现实性的人生。 把潜在性人生比喻为登山，可以这么来理解：如果登山的目的是登上山顶，那么它就是潜在性的行为，说得极端点，乘坐电梯登上山顶，逗留5分钟，然后再乘回电梯回来也可以。当然如果没能到达山顶的话，登山活动就等于失败。但是如果登山的目的不是登顶而是登山本身，那就可以说是现实性的活动，最终能不能登上山顶都没有关系。 人生中最大的谎言就是不活在“此时此刻”。纠结过去、关注未来，把微弱而模糊的光打下人生整体，自认为看到了些什么。甩开人生的谎言，毫不畏惧地把强烈的聚光灯打向“此时此刻”，我们可以做到。 人生很简单，并不是什么深刻的事情，如果认真的过好了每一个刹那，就没有什么必要令其过于深刻。 ","date":"2021-03-21","objectID":"/%E8%A2%AB%E8%AE%A8%E5%8E%8C%E7%9A%84%E5%8B%87%E6%B0%94/:0:0","tags":["思考"],"title":"被讨厌的勇气","uri":"/%E8%A2%AB%E8%AE%A8%E5%8E%8C%E7%9A%84%E5%8B%87%E6%B0%94/"},{"categories":["思考"],"content":"低阶、中阶、高阶的INTJ分别是怎么样的？ - 沉香的回答 - 知乎 https://www.zhihu.com/question/394452710/answer/1732110212 我认为划分低阶、中阶、高阶intj的标准是与社会的交互方式。 低阶intj intj对自我天然有着明确的认知，低阶intj同样，但此时低阶intj对自己在世界中的位置，或者社会中的自己是什么样没有清楚的认识，表现为狂妄自大，不屑真正去认识和接受这个社会的运作规律，不屑因为社会中的他人而改变自己的行为方式，不屑收敛自己对丑陋社会的厌恶、对他人的鄙夷和蔑视的态度，经常将“这个人是傻逼”直接写在脸上。 中阶intj 中阶intj会认识到自己狂妄的态度并不利于实现目标或终极理想。这一阶段，intj开始探索自己与社会的交互，试图就“如何在这个社会中实现自己的目标”给出答案，包括真正开始对社会的运作规律形成自己的认识，如何利用这一规律实现自己的目标，自己该进行什么改变、以什么样的方式与社会的交互可以达到最小阻力（减少阻碍）和最大收益以实现自己的目的。这一阶段的intj对更高阶的intj尤为关注，因为此时intj可以通过他们已经形成的社会交互认识和决策来完善自己。intj对世界、社会、人类、自我、情感的观念在这一阶段会以更快的速度不断变化完善。而intj也将不断通过实践探索何种方式是最佳的与社会交互的方式，此时intj会变得更加谦卑，更多地模拟其他人格，也可能反复出现对自己、对自己的世界观等种种观念怀疑的情况，与低阶intj对自己人格非常自信的态度形成对比。 高阶intj 高阶intj将重回对自己人格自信的态度，这种自信的态度建立在中阶时对世界、社会、自我不断修正后所得到的完善成熟的观念，建立在中阶时通过思考和实践总结形成的最佳与社会交互的方式，此时，高阶的intj应当已在他人看来有所成就，并因为自我观念的完善和世俗的成就，intj对其他人格的模拟程度和时间会降低，在如何与社会交互时以最小阻碍、最大收益以及如何能够展现真正的自我（intj不喜欢伪装，伪装只是权宜之计）实现平衡。 我不认为intj存在最终的完全完美的形态，到某一阶段就停止发展，呈现完美的状态。多数intj都以完美为目标，但intj会一直处于不断发展不断完善的状态。intj有着无穷发展完善的空间。 ","date":"2021-03-21","objectID":"/intj%E5%88%92%E5%88%86/:0:0","tags":["思考"],"title":"INTJ划分","uri":"/intj%E5%88%92%E5%88%86/"},{"categories":["思考"],"content":" 一个人对痛苦的感受能力和对无聊的感受能力成反比，这是由一个人的精神能力的大小所决定的。也就是说，一个人精神的迟钝一般是和感觉的迟钝和缺乏兴奋密切相关的，因此，精神迟钝的人也就较少感受到各种强度不一的痛苦和要求。但是，精神迟钝的后果就是内在的空虚。这种空虚烙在了无数人的脸上。并且，人们对于外在世界发生的各种事情——甚至最微不足道的事情——所表现出的一刻不停的、强烈的关注，也暴露出他们的这种内在空虚。人的内在空虚就是无聊的真正根源，它无时无刻不在寻求外在刺激，试图借助某事某物使他们的精神和情绪活动起来。 人们在这个世界上要么选择独处，要么选择庸俗，除此以外再没有更多别的选择了。 无论身在何处，我们只能在我们自身寻找或者获得幸福 无论在任何年龄阶段，一个人的自身拥有都是真正的和唯一持久的幸福源泉。我们这个世界乏善可陈，到处充斥着匮乏和痛苦，对于那些侥幸逃过匮乏和痛苦的人们来说，无聊却正在每个角落等待着他们。 我们之所以感到不满，原因就在于我们不断试图提高我们的要求，但同时，其他妨碍我们成功的条件因素却保持不变。 我们在这世上时日不多，不值得在可鄙的坏蛋的脚下爬行。 骂他人的人表明自己无法拿出被谩骂者的真正、确实的过错；否则，他就会把这些作为前提交代出来，然后充满信心地把结论留给他的听众去完成。但他却不是这样做。他提供了结论，但却说不出前提。他只能托词说这样做只是为了简便。 一个人的修改越独特、越具有价值和意义，那么，他就越有必要不时地认清自己生命总体发展的大致脉络和自己的计划，这对他大有好处。为此目的，他当然要踏上“认识自己”[7]的第一步，亦即了解清楚自己的首要和真正的意愿——这些对于他的幸福而言是至为重要的东西；然后，对于何者排在第二和第三位置必须心中有数。同时，他也应该大致上明白自己应该从事何种职业、需要扮演何种角色以及自己与这一世界的关系。如果一个人具备非凡的个性，那么，对自己的生命计划有一个大概的了解，能够比任[128]何一切都更有效地增强自己的勇气，振作、鼓足信心，激励自己行动起来，避免走进弯路。 正如一个旅行者只有在抵达了一处高地以后，才能够回头总体、联贯地看到自己所走过的迂回曲折的道路，同样，只有当我们度过了生命中的一段时间，或者在我们的整体生命终结的时候，我们才能把我们的做事、业绩和创作的作品真正联系起来，包括其中确切的因果关联，甚至才能了解到它们的价值。只要我们仍然置身其中，那么我们的行事就只能总是遵循我们那固定不变的性格构成，受着动机的左右和我们能力的制约。由此可见，我们的行事自始至终都有其必然性，我们在每一刻都做着我们在那一刻认为合理和适当的事情。只有事后的结果才让我们看清到底发生了什么事；对事情整体的回顾才使我们明白事情的如何和为什么。 人生智慧的重要一点就是在关注现在和计划将来这两者之间达致恰到好处的平衡，这样，现在与将来才不至于互相干扰。许多人太过沉迷于现在，这些是无忧无虑、漫不经心的人；也有的人则更多地活在将来，他们则是谨小慎微、忧心忡忡的杞人。人们很少能够在处理现在和将来两者当中把握一个恰到好处的尺度。 无论事情多么悲痛，我们必须让过去的事情成为过去，或许我们难以做到这一点，但我们必须降伏我们的乖僻心情。——荷马 要过一种深思熟虑的生活，并且能从生活经验中汲取一切有益的教训，我们就必须勤于反省，经常回顾做过的事情和曾经有过的感觉和体验；此外，还要把我们以前对事情的判断和现在的看法，以前订下的计划及追求和最终得到的结果及满足互相比较。这是为获得人生经验所做的单独的反复温习。一个人的生活经历可被视为一本书的正文，而对生活经历的咀嚼和认识则是对正文做出的解释。如果一个人有太多的反省和认识，但生活经历却又很少，那就好比只有两行正文，但注解却有四十行之多。如果一个人阅历很广，但却对此甚少反省，获得的认识又不多，这样，就好比一种比邦迪那版丛书——里面没有注解，正文的许多意思都不甚了了。 首先，生活在社交人群当中必然要求人们相互迁就和忍让；因此，人们聚会的场面越大，就越容易变得枯燥乏味。只有当一个人独处的时候，他才可以完全成为自己。谁要是不热爱独处，那他也就是不热爱自由，因为只有当一个人独处的时候，他才是自由的。拘谨、掣肘不可避免地伴随着社交聚会。社交聚会要求人们做出牺牲，而一个人越具备独特的个性，那他就越难做出这样的牺牲。因此，一个人逃避、忍受抑[136]或喜爱独处是和这一个人自身具备的价值恰成比例。因为在独处的时候，一个可怜虫就会感受到自己的全部可怜之处，而一个具有丰富思想的人只会感觉到自己丰富的思想。一言以蔽之：一个人只会感觉到自己的自身。进一步而言，一个人在大自然的级别中所处的位置越高，那他就越孤独，这是根本的，同时也是必然的。 完全、真正的内心平和和感觉宁静——这是在这尘世间仅次于健康的至高无上的恩物——也只有在一个人孤身独处[138的时候才可觅到；而要长期保持这一心境，则只有深居简出才行。 因为孤独是幸福、安乐的源泉。据此可知，只有那些依靠自己，能从一切事物当中体会到自身的人才是处境最妙的人。所以，西塞罗说过，“一个完全依靠自己，一切称得上属于他的东西都存在于他的自身的人是不可能不幸福的。” 一个人的自身拥有越多，那么，别人能够给予他的也就越少。正是这一自身充足的感觉使具有内在丰富价值的人不愿为了与他人的交往而作出必需的、显而易见的牺牲；他们更不可能会主动寻求这些交往而否定自我。相比之下，由于欠缺自身内在，平庸的人喜好与人交往，喜欢迁就别人。这是因为他们忍受别人要比忍受他们自己来得更加容易。此外，在这世上，真正具备价值的东西并不会受到人们的注意，受人注意的东西却往往缺乏价值。每一个有价值的、出类拔萃的人都宁愿引退归隐——这就是上述事实的证明和结果。 一个人对社会交往的热衷程度大致上与他的精神思想的价值成反比。 孤独为一个精神禀赋优异的人带来双重的好处：第一，他可以与自己为伴；第二，他用不着和别人在一起。第二点弥足珍贵，尤其我们还记得社会交往所意味着的束缚、烦扰甚至危险，拉布叶说过：“我们承受所有不幸皆因我们无法独处”。热衷于与人交往其实是一种相当危险的倾向，因为我们与之打交道的大部分人道德欠缺、智力呆滞或者反常。不喜交际其实就是不稀罕这些人。一个人如果自身具备足够的内涵，以致根本没有与别人交往的需要，那确实是一大幸事；因为几乎所有的痛苦都来自于与人交往，我们平静的心境——它对我们的幸福的重要性仅次于健康——会随时因为与人交往而受到破坏。没有足够的独处生活，我们也就不可能获得平静的心境。 孤独是困苦的；但可不要变得庸俗；因为这样，你就会发现[146]到处都是一片沙漠。 如果一个人出于对别人的有理由的厌恶，迫于畏惧而选择了孤独的生活，那么，对于孤独生活的晦暗一面他是无法长时间忍受的，尤其正当年轻的时候。我给予这种人的建议就是养成这样的习惯：把部分的孤独带进社会人群中去，学会在人群中保持一定程度上的孤独。这样，他就要学会不要把自己随时随地的想法马上告诉别人；另外，对别人所说的话千万不要太过当真。他不能对别人有太多的期待，无论在道德上抑或在思想上。对于别人的看法，他应锻炼出一副淡漠、无动于衷的态度，因为这是培养值得称道的宽容的一个最切实可行的手段。虽然生活在众人之中，但他不可以完全成为众人的一分子；他与众人应该保持一种尽量客观的联系。这样会使他避免与社会人群有太过紧密的联系，这也就保护自己免遭别人的中伤和侮辱。 从这种意义上说，我们可以把社会人群比喻为一堆火，明智的人在取暖的时候懂得与火保持一段距离，而不会像傻瓜那样太过靠近火堆；后者在灼伤自己以后，就一头扎进寒冷的孤独之中，大声地抱怨那灼人的火苗。 对于我们遭遇的每一桩不幸，我们都难辞其咎——至少在某种程度上是这样——并不是在每种情况下都绝对真实，虽然在大多数情况下事实的确如此。正因为人们对此真理有所感觉，所以，人们才尽最大可能地遮掩和粉饰自己遭遇到的不幸，并且竭力装出一副若无其事的样子：他们担心别人从他们的不幸遭遇推断出他们的罪责。 因此，对任何关乎我们痛苦和快乐的事情都应该以理性和判断力去观察和考虑，那也就是进行冷静的、不掺带个人情绪的思考，运用纯粹的概念在抽象中操作。我们不应该让思考掺杂着想象，因为想象没有能力对事情作出判断。相反，想象只会带来扰乱我们情绪的清晰图像，陡增我们的痛苦，而不会有任何好处。 要留意那严肃的时光，因为它甚少来临。——歌德 参与修建一座建筑物的工人，并不会知道这座建筑物的总体规则；或者，他们不会在心里时刻记住这一规划。同样，一个人在度过生命中每一小时，每一天的时候，对于自己的总体生命进程及其特征也不甚了解。一个人的修改越独特、越具有价值和意义，那么，他就越有必要不时地认清自己生命总体发展的大致脉络和自己的计划，这对他大有好处。为此目的，他当然要踏上“认识自己”[7]的第一步，亦即了解清楚自己的首要和真正的意愿——这些对于他的幸福而言是至为重要的东西；然后，对于何者排在第二和第三位置必须心中有数。同时，他也应该大致上明白自己应该从事何种职业、需要扮演何种角色以及自己与这一世界的关系。 但是，不管怎么[182]样，我们不应为此感到泄气，不要以为抽象的准则和格言无法指引我们的生活行为，因而放任自己。一切把理论性的规则应用于实际当中的工作都碰到同样的情况。首要的事情是明白和理解规律准则，其次则是具体学会应用这些准则。前者我们运用理性一次性就能做好；后者则需要我们进行循环渐进的练习。 在这里，我想对一切造作的行为发出警告：造作的行为总会引起别人的鄙视。首先是因为它造假和欺骗，这样，它就是懦弱的行径，因为欺骗源自于恐惧；其次，造作是我们对自己的某种自我谴责和贬","date":"2021-03-21","objectID":"/%E4%BA%BA%E7%94%9F%E7%9A%84%E6%99%BA%E6%85%A7/:0:0","tags":["思考"],"title":"人生的智慧","uri":"/%E4%BA%BA%E7%94%9F%E7%9A%84%E6%99%BA%E6%85%A7/"},{"categories":["思考"],"content":"INTJ 的痛苦来源于哪里，又应该怎样解决? https://www.zhihu.com/question/389163913/answer/1417576579 《你不懂我，我不怪你》 每个人都有一个死角， 自己走不出来，别人也闯不进去。 我把最深沉的秘密放在那里。 你不懂我，我不怪你。 每个人都有一道伤口， 或深或浅，盖上布，以为不存在。 我把最殷红的鲜血涂在那里。 你不懂我，我不怪你。 每个人都有一场爱恋， 用心、用情、用力，感动也感伤。 我把最炙热的心情藏在那里。 你不懂我，我不怪你。 每个人都有一行眼泪， 喝下的冰冷的水，酝酿成的热泪。 我把最心酸的委屈汇在那里。 你不懂我，我不怪你。 每个人都有一段告白， 忐忑、不安，却饱含真心和勇气。 我把最抒情的语言用在那里。 你不懂我，我不怪你。 你永远也看不见我最爱你的时候， 因为我只有在看不见你的时候，才最爱你。 同样， 你永远也看不见我最寂寞的时候， 因为我只有在你看不见我的时候，我才最寂寞。 也许，我太会隐藏自己的悲伤。 也许，我太会安慰自己的伤痕。 也许，你眼中的我，太会照顾自己， 所以，你从不考虑我的感受。 你以为，我可以很迅速的恢复过来，有些自私的以为。 从阴雨走到艳阳，我路过泥泞、路过风。 一路走来，你不曾懂我，我亦不曾怪你。 我不是为了显示自己的大度， 也不是为了体现自己的大方。 只想让你知道，感情不在，责备也不存在。 ","date":"2021-03-21","objectID":"/3%E6%9C%884%E6%97%A5%E6%80%BB%E7%BB%93/:0:0","tags":["思考"],"title":"3月4日总结","uri":"/3%E6%9C%884%E6%97%A5%E6%80%BB%E7%BB%93/"},{"categories":["思考"],"content":"3月1日，从家回到了学校，虽然已经出成绩两天，依然没能走出失败的阴霾。是的，考研失败了，一次又一次的冲击着我的心，这就是现实，时间是单向的，我们无法掌控。人总有一个无谓的假象，如果回到当时没有做错事，现在会是什么结果。这当然是实现不了的，我们还是那么憧憬，因为遗憾，和不成熟。我到底什么时候能独当一面，我到底什么时候能泰然处世，我到底什么时候能成熟做事？无数的疑问涌上心头，难道我没有才能吗？难道我没有努力吗？难道我注定要经历失败？我的内心不堪重负，开始放空，开始逃避这些沉重的问题，渐渐的，我的心开始冰冷，不再有了当年的一腔热血，有了很多负面想法，我懒惰，我自负，我逃避，我又一次开始讨厌我自己，我一直以来到底在坚持什么？我所谓的坚持难道就只是我不想适应社会的借口吗？我的努力就一文不值吗？没有回答。 黑暗中的微光仿佛隐隐说到，行动起来啊，接受平凡的自己，踏实努力的往前走啊。 致大学中迷茫且什么也没做好的自己：就算痛苦，迷惘，失望，也要勇敢去做啊！ ","date":"2021-03-21","objectID":"/3%E6%9C%881%E6%97%A5%E6%80%BB%E7%BB%93/:0:0","tags":["思考"],"title":"3月1日总结","uri":"/3%E6%9C%881%E6%97%A5%E6%80%BB%E7%BB%93/"},{"categories":["思考"],"content":"考研失败的事实已经接受了，本就是学过概率论的人，对概率这套可以说是再熟悉不过了，但在看到自己过校线的时候，心里还是那么激动，今年进复试确实是小概率事件，看到复试线时候还能平静面试也说明自己心里早就接受这个事实了，残酷吗，不残酷吗，都说不上，只是遗憾，但遗憾吗，仅凭去年不成熟的自己，就算再来一次，就能成功了吗，自怨自艾，自暴自弃，很正常，但我已经逐渐成熟了，我要利用4月之前的这十天，充分规划自己的人生，去实践，去了解，去探索，消除自己所有的假设，跟刘晴老师探讨读博士这条路，看看走过来的人对读博的看法，还有就是路上遇到的困难，跟宁哥探讨一下，自己不成熟的地方，看看跟那些成功的人身上有哪些自身不具备的品质，最后就是自己了，这十天可能不会是满负荷，闲暇时间多看一些书，很多时候我们困囿于一些烦恼之中无法脱身，很大程度因为我们想不清楚，就像王小波写的一只特立独行的猪，他在那个不思考的社会，自身看书思考解决了自己很多困惑，所以我们多读书的道理就在其中，饱读书的智者往往是波澜不惊的，他们对世界，社会，自身的思考非常通透，引用钢之炼金术师中的一句话，一即全，全即一，我们自身都和烧瓶小人，贪婪等人造人很像，盲目去追求一些东西，很少去思考我们真正想要的东西是什么，最后要么在生命结束的一瞬想通满足，要么无疾而终。人生短暂，没有很多时间去探索，这就要求我们每天都尽力去思考，即使痛苦，即使越想越迷惑，但这是人生的首要问题，即方向选对了，走的再慢也是在向终点靠近。 多看书，多思考，多实践。 ","date":"2021-03-21","objectID":"/3%E6%9C%8821%E6%97%A5%E6%80%BB%E7%BB%93/:0:0","tags":["思考"],"title":"3月21日总结","uri":"/3%E6%9C%8821%E6%97%A5%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"全自动的彩色眼底图像分割是自动化的眼底疾病筛查系统和辅助诊断系统的基础，能大大改善传统眼底疾病筛查和诊断的流程，降低眼科医生的阅片的工作量，优化医疗资源的配置。眼底图像中常见的结构包括血管、视盘和视杯，对于眼疾患者，可能还存在病灶，如渗出、微动脉瘤等。结构的形态变化以及病灶的有无、病灶的面积和数量等是眼疾诊断的重要临床依据。 眼底图像分割方法是语义分割方法在分析眼底图像中的具体应用。语义分割可以表述为带有语义标签的像素分类问题，其对图像所有像素使用一组对象类别（如人、车、树、天空）进行像素级标记，因此通常比预测整个图像隶属单个标签的图像分类困难。本文总结了现有的基于深度学习的语义分割方法，介绍常用数据集，网络架构，损失函数等。 Fully automatic color fundus image segmentation is the basis of the automated fundus disease screening system and auxiliary diagnosis system, which can greatly improve the traditional fundus disease screening and diagnosis process, reduce the workload of ophthalmologists, and optimize the allocation of medical resources . Common structures in fundus images include blood vessels, optic discs, and optic cups. For patients with eye diseases, there may be lesions such as exudation and microaneurysms. The morphological changes of the structure, the presence or absence of lesions, the area and number of lesions, etc. are important clinical evidence for the diagnosis of eye diseases. Fundus image segmentation method is the specific application of semantic segmentation method in analyzing fundus image. Semantic segmentation can be expressed as a pixel classification problem with semantic labels, which uses a set of object categories (such as people, cars, trees, and sky) to mark all pixels of the image at the pixel level. Therefore, it is usually more difficult than predicting that the entire image belongs to a single label. This article summarizes the existing semantic segmentation methods, introduces commonly used data sets, network architectures, loss functions, etc. 绪论 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:0:0","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"研究背景与意义 视网膜血管网络是唯一可以在体内可视化和拍照的血管系统。视网膜血管成像能够为患有特定心血管疾病和眼科疾病的患者提供临床预后信息.当前，视网膜血管分割高度依赖于经验丰富的眼科医生的手工工作，这是繁琐，耗时且可再现性低的。因此，迫切需要一种全自动且准确的视网膜血管分割方法，以减少眼科医生的工作量，并提供客观，精确的视网膜血管异常测量。有几个因素使这项任务具有挑战性。血管的长度和口径因对象而异。血管，血管边界，视盘和中央凹等各种病变的存在（包括出血，渗出液，微动脉瘤和纤维化带）可与血管混淆。此外，血管的相对低的对比度和一些眼底图像的低质量进一步增加了分割难度。视网膜是人类眼球后部的所谓眼底。眼底图像中有许多小血管，唯一可以无创地直接观察到的是人体深部血管。与年龄相关的黄斑变性，还有其他一些眼部疾病也与高血压，动脉粥样硬化和糖尿病等疾病密切相关。分割血管并从眼底图像中提取血管特征，使得医生可以快速诊断和确定病情并提高诊断效率，这是非常重要的。 青光眼是目前发病率率最高的视神经疾病之一，截至目前，全世界的青光眼患者的人数已经达到七千万以上。青光眼是由眼内压升高而引起的视神经纤维损伤所致，这是一种不可逆的损伤，没有自愈的可能。并且青光眼术后失明率也是非常之高。青光眼早期是没有明显的症状的，但随着疾病的进展，患者会逐渐失去视力。等到出现视力不佳且难以识别的患者去医院就诊，往往已进入青光眼末期，此时视神经纤维很可能已经严重受损且难以康复。中国是世界上青光眼患者最多的国家，所以研究开发一种可以自动诊断识别青光眼的医疗系统迫在眉睫。杯盘比指的是视杯直径与视盘直径之比。通常来说，正常眼底的杯盘比值为0.3 至 0.5。如果杯盘比值超过了0.5，则怀疑患者有可能是青光眼。所以使用人工智能算法实现自动进行视杯视盘分割具有重要意义。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:1:0","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"语义分割方法总结 学术界已经有了很多成熟的图像分割方法，从最早的直方图阈值化方法，特征空间聚类方法，区域增长方法和SVM及随机森林等机器学习方法等，到近年卷积神经网络的兴起，衍生出了大量创新性的工作，包括全卷积网络，编码器-解码器结构，多尺度提取特征和基于金字塔的方法，递归神经网络，视觉注意力模型，以及生成对抗模型等。 眼底图像分割方法研究课题分析 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:2:0","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"视杯和视盘分割 青光眼是一种慢性眼病，会使视神经退化，导致视杯(OC)与视盘(OD)之间的比率很大。在临床上，杯盘比(CDR)是由专业眼科医生手动估计的。这是耗费体力和时间的。为了使准确的彩色多普勒血流图的定量自动化，并辅助青光眼的诊断，OD和OC的分割越来越受到重视。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:3:0","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"血管分割 眼球底部的视网膜血管是全身血管系统中唯一可以无创直接观测到的部分, 其自身的变化, 例如血管宽度、角度、分支形态等, 均可作为与血管相关疾病的诊断依据。眼科致盲疾病, 例如青光眼、糖尿病视网膜病变、老年性黄斑病变等, 能直接从眼底视网膜血管病变中观察到。 深度学习背景下的语义分割方法综述 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:4:0","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"术语及背景知识 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:5:0","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"语义分割 语义分割是对一张图像进行像素级的分类。由于语义分割问题被定义为像素级，意味着仅仅是图像的分类是不够的，还需要在原图像上进行以像素级的分辨率进行定位。 更加正式的明确语义分割任务如下： 输入： $R^{H \\times W \\times 3}$ 常规的图片，其中H和W分别代表输入图片的高和宽。 输出： $R^{H \\times W \\times classNum}$ classNum为给定的数据集的类别数，也就是一共classNum个通道的H*W大小的特征图。每一个通道对应一 class,对每一个像素位置，都有classNum个通道,每个通道的值对应那个像素属于该class的预测概率。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:5:1","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"卷积神经网络 卷积神经网络（Convolutional Neural Network）主要由三部分组成： 1.卷积层，使用卷积核（或滤波器）提取特征。 2.非线性层，在特征图上（通常是逐元素地）应用激活函数，以便通过神经网络对非线性函数进行建模。 3.池化层，池化层用一些统计数据替换了特征图的小范围邻域（平均值，最大值等），降低空间分辨率。 每个单元都从前一层中较小的邻域（称为感受野）接收加权输入。通过堆叠层数以形成多分辨率金字塔， 高层可以从越来越宽的感受野中学习特征。 CNN的主要计算优势在于，同层的卷积核相同，共享权重，因此与完全连接的神经网络相比，参数数量明显减少。一些最著名的CNN架构包括：AlexNet，VGGNet，ResNet，GoogLeNet和MobileNet。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:5:2","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"RNN和LSTM RNN被广泛用于处理顺序数据，例如语音，文本，视频和时间序列，其中任何给定时间或位置的数据都取决于先前遇到的数据。在每个时间戳上，模型都会收集当前时间$\\mathop X\\nolimits_i$的输入和上一步$\\mathop h\\nolimits_{i - 1}$的隐藏状态， 并输出目标值和新的隐藏状态。RNN通常在长序列方面存在问题，因为在许多实际应用中它们无法捕获长期依赖关系（尽管它们在这方面没有任何理论上的限制），并且经常遭受梯度消失或爆炸问题的困扰。长短时记忆网络旨在避免这些问题。LSTM体系结构包括三个门（输入门，输出门，遗忘门），通过门控状态来控制传输状态，记住需要长时间记忆的，忘记不重要的信息。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:5:3","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"编码器-解码器和自编码器模型 由编码函数编码器-解码器模型是一组模型，可以学习通过两级网络将数据从输入域映射到输出域：由编码函数 $z = f(x)$ 表示的编码器将输入压缩为潜在空间表示；解码器 $y = g(z)$旨在预测潜在空间表示的输出。这里的潜在表示本质上是指特征（矢量）表示，它能够捕获底层的输入的语义信息，可用于预测输出。这些模型在图像到图像的翻译问题以及NLP中的序列模型中非常流行。重建损失用于测量ground-truth $y$和后续重建$\\hat{y}$之间的差异。通常通过最小化重建损失$L(y, \\hat{y})$来训练这些模型。此处的输出可以是图像的增强版本（例如，在图像去模糊或超分辨率中）。自编码器是编码器-解码器模型的特例，其中输入和输出相同。最受欢迎的一种是堆叠式降噪自编码器（SDAE），它可以堆叠多个自编码器并将其用于图像降噪。另一个流行的变体是变体自编码器（VAE），它在潜在表示上施加了先验分布。VAE能够根据给定的数据分布生成实际样本。对抗性自动编码器是另一种变体，它在潜在表示上引入对抗性损失，以使它们近似先验分布。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:5:4","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"Transformer Transformer有一个编码器-解码器结构。编码器由六个相同的层组成，每层有两个子层:一个多头自注意力模块和一个简单的全连接前馈网络。如图所示，在每一层之后，使用残差连接和层标准化。注意，不同于同时执行特征聚集和特征变换的常规卷积网络(例如，卷积层之后是非线性)，这两个步骤在Transformer模型中是解耦的，即自注意力层仅执行聚集，而前馈层执行变换。与编码器类似，Transformer模型中的解码器包含六个相同的层。每个解码器层有三个子层，前两个子层(多头自注意力和前馈)类似于编码器，而第三子层对相应编码器层的输出执行多头注意力。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:5:5","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"迁移学习 在某些情况下，可以在新的数据集上从头开始训练深度学习模型（假设有足够数量的已标记训练数据），但是在许多情况下，没有足够的已标记数据来从头开始训练模型，可以使用迁移学习解决这个问题。在迁移学习中，经过对新任务的适应，将在一个任务上训练的模型重新用于另一相关任务。例如，可以使在ImageNet上训练的图像分类模型适应不同的任务，例如纹理分类或面部识别。在语义分割的情况下，许多人使用在ImageNet上训练的模型（比大多数图像分割数据集更大的数据集）作为网络的编码器部分，并从这些初始权重中重新训练他们的模型。预训练的模型应该能够捕获分割所需图像的语义信息，因此能够用较少已标记样本来训练模型。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:5:6","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"数据集 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:6:0","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"STARE(structured snalysis of the retinal) STARE 是 1975 年由 Michael Goldbaum 发起的项目, 它在 2000 年由 Hoover等首次在论文中引用并公开，是用来进行视网膜血管分割的彩色眼底图数据库,包括 20 幅眼底图像, 其中 10 幅有病变, 10 幅没有病变, 图像分辨率为 605×700, 每幅图像对应 2 个专家手动分割的结果,是最常用的眼底图标准库之一.。但是其自身的数据库中没有掩膜，需要自己手动设置掩膜。目前它已扩展到40 幅血管分割手工标注结果和 80 幅视神经检测手工标注结果。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:6:1","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"DRIVE(digital retinal images for vessel extraction) DRIVE是 Niemeijer 团队在 2004年根据荷兰糖尿病视网膜病变筛查工作建立的彩色眼底图库。 其图像是从 453 名 25 90 岁的不同个体拍摄得到,随机抽取了其中 40 幅, 其中 7幅是有早期糖尿病视网膜病变的, 33 幅是没有糖尿病视网膜病变的眼底图,每幅图像的像素为 565×584. 分成训练集和测试集, 每个子集 20 幅图像,每幅图像对应 2个专家手动分割的结果.其自身有专门的掩膜，调用方便。比较好的运用到监督学习和深度学习的图像训练当中。该库是衡量视网膜血管分割方法性能好坏的最常用数据库。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:6:2","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"IDRiD(Indian Diabetic Retinopathy Image Dataset) IDRiD的图像是由位于印度的一家眼科诊所的视网膜专家拍摄的。从数以千计的有效检测中，提取了516张图像来构成数据集。专家证实，所有图像均具有足够的质量，临床相关性，没有图像重复并且存在糖尿病视网膜病变（DR）和糖尿病黄斑水肿（DME）的疾病分层的合理混合。它是唯一一个由典型糖尿病视网膜病变和正常视网膜结构组成的数据集。该数据集提供关于糖尿病视网膜病的疾病严重程度以及每张图像的糖尿病黄斑水肿情况。数据集具体由81个带有DR标记的彩色眼底图像组成。提供与DR相关的异常的精确像素级注释，例如微动脉（MA），软性渗出（SE），硬性渗出（EX）和出血（HE）的二值化掩膜，用于评估单个病变分割技术的性能。它包括彩色眼底图像（.jpg文件）和由病变组成的二值化掩码（.tif文件）。除了所有异常图像之外，还提供了所有81张图片的视杯视盘区域的二值化掩膜。根据国际临床糖尿病视网膜病变量表，将糖尿病视网膜图像分为不同的组。黄斑水肿的严重程度是根据在斑点中心区域附近出现的硬分泌物而决定的。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:6:3","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"OIA(Ophthalmic Image Analysis) OIA-DDR数据集和OIA-ODIR数据集是OIA系列数据集的两个子集。其中，OIA-DDR数据集包含13673张眼底图像，包含了四种糖尿病视网膜病变相关的病变点的标注，757张包含像素级和bounding-box级的病变点标注。OIA-ODIR数据集包含10000张眼底图像，取样人群年龄涵盖全年龄段人群，其中30周岁至80周岁的人群占比超过96%；该数据主要针对眼部多疾病同步诊断，每张眼底图像包含8个疾病标签，分别为：正常N、糖网病D、青光眼G、白内障C、老年黄斑变性A、高血压H、近视M、其他疾病/异常O。OIA-ODIR数据集是基于一张眼底图像的多类型病变检测数据集。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:6:4","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"REFUGE(Retinal Fundus Glaucoma Challenge) REFUGE公布了1200张针对青光眼的眼底彩色图像数据，评估和比较数据集上的青光眼检测、视盘/杯分割及黄斑中心凹定位的自动算法。该数据库是目前青光眼眼底照片精标数据库中最全面的标注数据库，主要包括青光眼与非青光眼两种类型数据，其中青光眼和非青光眼图像的比例分别为10% 和90%。每张眼底图像分别包含诊断、图像分割及定位三方面信息，由七位专家人工标记并融合，克服了之前许多青光眼公开数据集存在的只有诊断标签信息，无视杯、视盘等关键结构的标注信息，且参与标注的专家较少等缺点。所有图像均以后极（postserior pole）为中心，同时含有黄斑和视盘。在这个数据集中，由训练集、验证集和测试集三个组成。训练集中有400 张像素为 2142 × 2056 的眼底图像，是使用 Zeiss Visucam 500眼底相机拍摄的，而验证集和测试集各由 400 张像素均为 1 634 × 1634的眼底图像组成，是使用 Canon CR-2 眼底相机拍摄的。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:6:5","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"评价指标 对于k+1类（k个前景类和背景类），其中$\\mathop p\\nolimits_{ij}$是类别i的像素被预测为类别j的像素数。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:7:0","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"Pixel Accuracy (PA) 分类正确的像素点数和所有像素点数的比例。 $$PA = \\frac{{\\sum\\nolimits_{i = 0}^k {\\mathop p\\nolimits_{ii} } }}{{\\sum\\nolimits_{i = 0}^k {\\sum\\nolimits_{j = 0}^k {\\mathop p\\nolimits_{ij} } } }}$$ ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:7:1","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"Mean Pixel Accuracy (MPA) 逐类计算正确分类像素和所有像素点数比例，然后求平均。 $$MPA = \\frac{1}{{k + 1}}\\sum\\limits_{i = 0}^k {\\frac{{\\mathop p\\nolimits_{ii} }}{{\\sum\\nolimits_{j = 0}^k {\\mathop p\\nolimits_{ij} } }}}$$ ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:7:2","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"Intersection over Union (IoU) or the Jaccard Index 预测分割图和真实分割图之间的交集面积与并集面积之比。 $$IoU = J(A,B) = \\frac{{|A \\cap B|}}{{|A \\cup B|}}$$ ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:7:3","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"Mean-IoU 所有类别的平均IoU $$MIoU = \\frac{1}{{k + 1}}\\sum\\limits_{i = 0}^k {\\frac{{\\mathop p\\nolimits_{ii} }}{{\\sum\\nolimits_{j = 0}^k {\\mathop p\\nolimits_{ij} + } \\sum\\nolimits_{j = 0}^k {\\mathop p\\nolimits_{ji} } - \\mathop p\\nolimits_{ii} }}}$$ ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:7:4","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"Precision/Recall/F1 score TP表示真阳性分数，FP表示假阳性分数，FN表示假阳性分数，FN表示假阴性分数。 $$Precision = \\frac{{TP}}{{TP + FP}}, Recall = \\frac{{TP}}{{TP + FN}}$$ F1分数是准确率和召回率的调和平均数。 $$F1 - score = \\frac{{2\\Pr ec{\\mathop{\\rm Re}\\nolimits} c}}{{prec + {\\mathop{\\rm Re}\\nolimits} c}}$$ ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:7:5","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"Dice coefficient 预测分割图和真实分割图的重叠区域的两倍与两分割图中像素的总数和之比。Dice系数和IoU呈正相关关系 $$Dice = \\frac{{2|A \\cap B|}}{{|A| + |B|}}$$ ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:7:6","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"语义分割模型 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:0","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"FCN 1.全卷积 通常CNN网络在卷积池化之后会接上若干个全连接层，将产生的特征图映射成为一个固定长度的特征向量。一般的CNN结构适用于图像级别的分类和回归任务，因为它们最后都期望得到输入图像属于各个类别的概率。FCN对图像进行像素级的分类，从而解决了语义级别的细粒度图像分割问题。与经典的CNN在卷积层后加全连接层得到固定长度的特征向量进行分类不同，FCN可以接受任意尺寸的输入图像，采用反卷积对最后的特征图进行上采样，使它恢复到输入图像相同的尺寸，从而可以对每一个像素都产生一个预测。全卷积网络从抽象的特征中恢复出每个像素所属的类别。即从图像级别的分类进一步延伸到像素级别的分类。 2.跳层连接 语义分割任务包括语义识别和目标定位两个方面。通常经过CNN多次卷积池化后得到的高层特征图可以反映抽象语义信息，低级特征图可以精确反映位置信息。权衡二者，使用跳层连接，将低层位置信息丰富的特征图和高层和高层语义信息丰富的特征图融合，提高语义分割性能。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:1","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"U-Net U-Net网络常用于医学图像分割。 1. U型对称结构。左侧为收缩路径即编码器，经过多次卷积池化缩小特征图，以提取高级语义特征，右侧是扩张路径即解码器，经过多次转置卷积扩大特征图，以将特征图解码还原成原图大小进行像素级分类。 2. U-Net网络的每个卷积层得到的特征图都会融合到对应的上采样层，从而实现每层特征图都有效使用到后续计算中，即跳层连接。U-Net结合了低级特征图和高级特征图，提高模型的结果精确度。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:2","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"Deeplab（V1 V2 V3 V3+） DeepLabv1 是由深度卷积神经网络和概率图模型级联而成的语义分割模型，由于深度卷积神经网络在重复下采样的过程中会丢失很多的细节信息，所以采用扩张卷积算法增加感受野以获得更多上下文信息，增大感受野可间接减少层数。使用全连接条件随机场来提高模型捕获细节的能力。 DeepLabv2 增加了 ASPP（Atrous spatial pyramid pooling）结构，利用多个不同采样率的扩张卷积提取特征，再将特征融合以捕获多尺度的上下文信息。 DeepLabv3 在 ASPP中加入了全局平均池化，同时在扩张卷积后添加批量归一化，有效地捕获了全局语境信息。 DeepLabv3+ 在 DeepLabv3 的基础上增加了编-解码模块和 Xception主干网络，增加编解码模块主要是为了恢复原始的像素信息，使得分割的细节信息能够更好的保留，同时编码丰富的上下文信息。增加Xception主干网络是为了采用深度卷积进一步提高算法的精度和速度。在inception结构中，先对输入进行1*1的卷积，之后将通道分组，分别使用不同的3*3卷积提取特征，最后将各组结果串联在一起作为输出。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:3","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"RefineNet RefineNet可以分为两部分，分别对应于U-Net中收缩（下采样提取语义特征）和扩张（上采样恢复细节信息）两段路径。收缩路径使用ResNet。扩张路径使用RefineNet，其得到的特征与ResNet中低级特征的融合。 RefineNet可以分为三个主要部分： 1.不同尺度的特征输入首先经过两个残差卷积单元处理。 2.不同尺度的特征进行融合。所有特征上采样恢复分辨率，然后进行加和。 3.最后经过链式残差池化模块。思想是分支上的卷积池化用于提取高级语义信息或者说背景上下文信息，与输入加和以达到融合高级语义信息和低级位置信息。最后再经过一个残差卷积单元即得RefineNet的输出。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:4","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"PSPNet 1.全局平均池化，替代全连接层，减少参数同时增加了先验知识以达到正则化的效果。 2.金字塔池化，生成的不同尺度的特征图最终被上采样恢复原图大小拼接起来，然后进行卷积调整通道数，进行Softmax分类。金字塔池化模块能收集不同尺度的语境信息并融合，会比全局池化所得的全局信息保留更多细节。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:5","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"GCN GCN全局卷积网络从两个设计原则出发： 1. 定位角度，使用全卷积结构，保留更多位置信息。 2. 分类角度，使用大尺寸卷积核，以达到在输入尺寸改变时保持感受野足够大。 GCN模块，卷积核的大小和各个尺度的特征图大小相同以提取全局信息，为了减少参数数量用，k x 1和1 x k两次卷积代替一次k x k卷积，1 x k 和 k x 1两次卷积代替一次1 x 1卷积，并且没有非线性操作。 BR模块，使用残差结构细化边界。 整体网络架构： 使用预训练的ResNet作为特征提取网络，FCN4作为分割框架，从特征提取网络的不同阶段提取多尺度的特征图，后接GCN模块用于生成每个类的多尺度语义分数图，BR模块用于细化边界。使用转置卷积对分辨率较低的分数图进行上采样，然后与分辨率较高的分数图相加，以生成新的分数图，在最后一次上采样后，生成语义分数图，用于输出预测结果。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:6","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"EncNet 之前引入全局上下文信息的方法大致有两个，扩张卷积和金字塔结构，但这两种方法都一定程度上割裂了单个像素和整个图像的关系。如果能够先捕获图像上下文信息(例如这是卧室)，然后，就可以根据背景语义缩小分类范围 (例如卧室里面有床、椅子等)，以动态的减少搜索范围。或者说，加入对于场景的先验知识，这样对图片中像素分类更有针对性。 EncNet使用上下文编码模块捕获图像全局信息，结合上下文信息给每个通道的特征图加权，以达到利用全局信息进行分割的效果。同时集成了语义编码损失（SE-loss）。一般方法逐像素计算交叉熵损失，不考虑全局上下文信息，SE-loss在编码层之上添加了一个带Sigmoid激活的全连接层单独用于预测场景中出现的类别，并计算二分类交叉熵损失，减少了图像中出现的类别噪声。不同于逐像素计算损失训练集大物体的像素数多于小物体，SE-loss 考虑大小不同的物体有相同的贡献，这能够提升小目标的检测性能。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:7","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"NonLocal Net 扩大感受野利用全局信息对语义分割很有帮助，全连接完整利用了全局信息，但是增加了大量参数，难以训练，卷积操作利用空间不变性减少了参数数量，但是只能利用局部信息，NonLocal Net利用注意力机制，每次计算都使用全部像素，同时计算相似度函数对其加权。这样既利用了全局信息又使网络容易训练。 $$\\mathop y\\nolimits_i = \\frac{1}{{C(x)}}\\sum\\limits_{\\forall j} {f(\\mathop x\\nolimits_i ,\\mathop x\\nolimits_j )g(\\mathop x\\nolimits_j )}$$ ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:8","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"PSANet 和NonLocal Net思想相同，主要区别如下： 1.有两个分支学习双向关系，分别起到collect和distribute的作用。 2.相关度矩阵$f$的计算。对于像素$i$，其相关度向量$f({x_i},x)$，通过施加在${x_i}$上的两个1 x 1卷积得到，即由$f({x_i},x)$ 变为$f({x_i})$，只和query和相对位置相关。 此外，PSANet包含两路attention，相当于Transformer中的两个head。两路分别起到collect和distribute的作用。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:9","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"DANet 和NonLocal Net思想相同，主要区别如下： 1. 使用双分支，分别是位置注意力机制和通道注意力机制方法。 2. 使用残差机制。 具体结构和Transformer相同。B，C，D矩阵分别对应Transformer中的Q，K，V。 $${s_{ji}} = \\frac{{\\exp ({B_i} \\cdot {C_j})}}{{\\sum\\nolimits_{i = 1}^N {\\exp ({B_i} \\cdot {C_j})} }}$$ $${E_j} = \\alpha \\sum\\limits_{i = 1}^N {({s_{ji}}{D_i}) + {A_j}}$$ $${x_{ji}} = \\frac{{\\exp ({A_i} \\cdot {A_j})}}{{\\sum\\nolimits_{i = 1}^C {\\exp ({A_i} \\cdot {A_j})} }}$$ $${E_j} = \\beta \\sum\\limits_{i = 1}^C {({x_{ji}}{A_i}) + {A_j}}$$ ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:10","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"CCNet 和NonLocal Net思想相同，主要区别如下： 将NonLocal Net中的${(H * W)^2}$次计算像素点之间的相似性简化成两次迭代计算当前像素点和同行同列的像素点之间的相似性，共${(H * W) *(H + W - 1)}$次计算，提升了计算效率。 {width=“0.5\\linewidth”} ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:11","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"APCNet 整体流程描述如下： 原始图片先经过CNN得到特征图，后接多个提取不同尺度特征ACM模块和原特征图结合组成最终特征图，后接卷积调整通道数量，最后预测结果。 ACM模块具体描述如下： ACM模块有两个分支组成，上面的分支用于计算亲和系数，亲和参数为单一尺度下h*w个像素对应s*2大小的贡献度权重矩阵，下面的分支用于提取单一尺度的特征图，最后将信和系数与特征图做矩阵乘法得到最终用于预测的特征图。 第一个分支先经过1*1卷积调整通道数为512即降维，之后做全局平均池化提取全局信息，与降维后得到的特征图相加，即使每个像素结合全局信息，再用1*1卷积降维成s*s个通道，最后reshape成hw*s*s的亲和系数矩阵。 第二个分支先经过自适应池化调整成s*s大小，后接1*1卷积调整通道数为512即初步得到s*s*512特征图，再和上面分支得到的亲和系数矩阵做矩阵乘法得到hw*512的特征图，最后采用了残差的思想将最终的特征图与1*1卷积后得到的h*w*512特征图相加最终得到了在s尺度下的特征表示。 总结: 1.利用了多尺度信息，即使用多个s值不同的ACM模块最后整合。 2.计算亲和系数矩阵前，每个像素整合了全局信息，所以使得到的亲和系数矩阵既有单个像素信息也有全局像素信息，以达到表示单个像素和全局像素相关性的效果。 3.引入注意力机制，即计算亲和系数矩阵。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:12","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"SENet $Ftr$是传统的卷积结构，X和U是$Ftr$的输入$(C' \\cdot H' \\cdot W')$和输出$(C \\cdot H \\cdot W)$，SENet增加的部分是U后的结构，即对U先做全局平均池化，输出1*1*C的向量后接两个全连接层，最后加Sigmoid函数将范围限制在0，1之间，把这个值作为放缩系数与对应通道相乘。 总结: 增加了有Squeeze压缩和Extraction解压两部分的分支用于得到放缩系数，把重要的通道增强，不重要的通道减弱，以实现注意力机制。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:13","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"GCNet 基于NonLocalNet和SENet，结合两者优点提出了GCNet，计算量相对较小，又能很好地融合全局信息。 NonLocal Net公式如下： $${z_i} = {x_i} + {W_z}\\sum\\limits_{j = 1}^{{N_p}} {\\frac{{f({x_i},{x_j})}}{{C(x)}}} ({W_v} \\cdot {x_j})$$ 对其中的attention map $\\frac{{f({x_i},{x_j})}}{{C(x)}}$ 可视化如下： 作者发现训练好的NonLocal Net中，对于图像中不同位置计算的attention map几乎一致。所以，作者对NonLocal Net进行了简化，通过计算一个全局的attention map来简化non-local block，并且对所有位置共享这个全局attention map。忽略 ${W_z}$，简化版的non-local block定义为： $${z_i} = {x_i} + \\sum\\limits_{j = 1}^{{N_p}} {\\frac{{\\exp ({W_k}{x_j})}}{{\\sum\\nolimits_{m = 1}^{{N_p}} {\\exp ({W_k}{x_m})} }}} ({W_v} \\cdot {x_j})$$ 为了进一步z减少简化版non-local block的计算量，将 ${W_v}$ 移到attention pooling的外面，表示为： $${z_i} = {x_i} + {W_v}\\sum\\limits_{j = 1}^{{N_p}} {\\frac{{\\exp ({W_k}{x_j})}}{{\\sum\\nolimits_{m = 1}^{{N_p}} {\\exp ({W_k}{x_m})} }}} {x_j}$$ 其结构如下： {width=“0.3\\linewidth”} 由于Transform结构中有大量参数，为了获得SENet轻量化的特点，1x1卷积用bottleneck transform模块替代，能显著降低参数量，思路即使用C x C/r，C/r x C/r和 C/r x C三次变换替代C x C一次变换，参数数量从C x C缩减为2 x C x C/r + C/r x C/r。因为两层bottleneck transform增加了优化难度，所以在ReLU前面增加一个layer normalization层。 最后GCNet结构如下： {width=“0.3\\linewidth”} ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:14","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"DMNet DCM模块具体如下： 第一个分支执行1 x 1卷积调整通道数为512，得到降维后特征图。 第二个分支先执行自适应池化将原图调整为k x k大小，后接1 x 1卷积调整通道数512，得到降维后卷积核，与降维后特征图进行卷积。 总结：特点是Context-aware filters使类似PSPNet的金字塔池化，将图片划分k x k个区域，使用多个k值不同的DCM模块即可达到多尺度信息融合，后接1 x 1卷积结果不做常规的特征图，而是作为卷积核，和上面分支得到的特征图进行卷积操作，个人理解相当于卷积核结合特征图信息进行了有意义的初始化，有利于卷积核参数的训练。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:15","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"ParseNet 为了整合全局信息，设计两条分支。 第一条分支先进行全局池化，平均池化或者最大池化，得到1 x 1 x C的特征向量，之后经过L2归一化，后接反池化恢复原特征图尺寸。 第二条分支对每一个像素位置的1 x 1 x C向量进行L2归一化，最后与第一条分支结果结合。 总结:利用简单的全局平均池化保留每个通道的特征图的全局信息，后接L2归一化。L2归一化的目的是消除量纲大小对特征选择的影响，防止出现在进行特征选择时，偏向数值大的特征，忽视数值小的特征。最后反池化以恢复原特征图尺寸，与经L2归一化的特征图结合得到最终特征。 ","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:16","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":["语义分割"],"content":"OCRNet 主要思想是显式地把像素分类问题转化成物体区域分类问题，这与语义分割问题的原始定义是一致的，即每一个像素的类别就是该像素属于的物体的类别，换言之，与PSPNet 和 DeepLabv3 的上下文信息最主要的不同就在于 OCR方法显式地增强了物体信息。假设backbone输出特征维度是b x c x h x w，共有k个类别。 OCR 方法的实现主要包括3个阶段： 1.根据网络中间层的特征表示估测一个粗略的语义分割结果作为 OCR方法的一个输入 ，即软物体区域（Soft Object Regions），具体是后接1 x 1卷积调整通道数，得到b x k x h x w的输出。 2.根据粗略的语义分割结果和网络最深层的特征表示计算出 k组向量，即物体区域表示（Object Region Representations），其中每一个向量对应一个语义类别的特征表示（因为组略的语义分割结果包含了物体区域信息，相当于用每个物体区域的mask和像素特征表示做矩阵乘法），具体是b x c x h x w的Pixel Representations和 b x k x h x w 的转置做矩阵乘法得到b x k x c输出即Object Region Representations。 3.计算网络最深层输出的像素特征表示PR（Pixel Representations）与计算得到的物体区域特征表示ORR（Object Region Representation）之间的关系矩阵，然后根据每个像素和物体区域特征表示在关系矩阵中的数值把物体区域特征加权求和，得到最后的物体上下文特征表示 OCR (Object Contextual Representation) 。具体是b x k x c的ORR和b x c x h x w的PR做矩阵乘法得到b x k x h x w的输出，再在维度k加上Softmax函数转化为attention map同时也是解码器即PRR（Pixel-Region Relation），再对PRR和ORR做矩阵乘法得到b x c x h x w的OCR。当把物体上下文特征表示 OCR 与网络最深层输入的特征表示拼接之后作为上下文信息增强的特征表示（Augmented Representation），可以基于增强后的特征表示预测每个像素的语义类别。综上，OCR可计算一组物体区域的特征表达用于表示每一类物体的区域特征，然后根据物体区域特征表示与像素特征表示之间的相关性，得到结合物体区域特征的像素特征表示。 参考文献 Liu Q, Zou B, Zhao Y, et al. A Deep Gradient Boosting Network for Optic Disc and Cup Segmentation[C]//ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE,2020: 971-975. Kirbas C, Quek F A review of vessel extraction techniques and algorithms[J]. ACM Computing Surveys, 2004, 36(2): 81-121 Minaee S, Boykov Y, Porikli F, et al. Image segmentation using deep learning: A survey[J]. arXiv preprint arXiv:2001.05566, 2020. Long J, Shelhamer E, Darrell T. Fully convolutional networks for semantic segmentation[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2015: 3431-3440. Ronneberger O, Fischer P, Brox T. U-net: Convolutional networks for biomedical image segmentation[C]//International Conference on Medical image computing and computer-assisted intervention. Springer, Cham, 2015: 234-241. Chen L C, Papandreou G, Kokkinos I, et al. Semantic image segmentation with deep convolutional nets and fully connected crfs[J]. arXiv preprint arXiv:1412.7062, 2014. Chen L C, Papandreou G, Kokkinos I, et al. Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs[J]. IEEE transactions on pattern analysis and machine intelligence, 2017, 40(4): 834-848. Chen L C, Papandreou G, Schroff F, et al. Rethinking atrous convolution for semantic image segmentation[J]. arXiv preprint arXiv:1706.05587, 2017. Chen L C, Zhu Y, Papandreou G, et al. Encoder-decoder with atrous separable convolution for semantic image segmentation[C]//Proceedings of the European conference on computer vision (ECCV). 2018: 801-818. Lin G, Milan A, Shen C, et al. Refinenet: Multi-path refinement networks for high-resolution semantic segmentation[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 1925-1934. Zhao H, Shi J, Qi X, et al. Pyramid scene parsing network[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 2881-2890. Peng C, Zhang X, Yu G, et al. Large kernel matters–improve semantic segmentation by global convolutional network[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 4353-4361. Zhang H, Dana K, Shi J, et al. Context encoding for semantic segmentation[C]//Proceedings of the IEEE conference on Computer Vision and Pattern Recognition. 2018: 7151-7160. Wang X, Girshick R, Gupta A, et al. Non-local neural networks[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2018: 7794-7803. Zhao H, Zhang Y, Liu S, et al. Psanet: Point-wise spatial attention network for scene parsing[C]//Proceedings of the European Conference on Computer Vision (ECCV). 2018: 267-283. Fu J, Liu J, Tian H, et al. Dual attention network for scene segmentation[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019: 3146-3154","date":"2021-03-03","objectID":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/:8:17","tags":["语义分割"],"title":"语义分割总结","uri":"/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"中南大学本科生 ","date":"0001-01-01","objectID":"/about/:0:0","tags":null,"title":"About","uri":"/about/"}]